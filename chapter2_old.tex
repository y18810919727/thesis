% !Mode:: "TeX:UTF-8"

\chapter{文献综述}
\section{复杂动态系统建模预测方法概述}
\subsection{基于自回归模型的动态系统预测}
最早追溯到1950年，为了进行控制系统设计，文献[17]首次提出了系统识别的概念用来建模动态系统。传统系统识别方法已经发展为一个非常完善且成熟的研究领域
\cite{le2013system,gevers2006personal,ljung2008perspectives,ljung2011four,Ljung2020}。
系统辨识的核心目标是寻找一个与系统“相符”的模型，使得模型的输出 尽量接近真实的输出。

系统通常是由表征系统输入输出关系的数学模型描述的，这个模型有其特定的结构和参数。以代数方程表示的系统称为静态系统，
考虑最简单的形式，系统的连续时间模型可以建模为常系数微分方程：
\begin{equation}
\frac{\mathrm{d}^{n} y(t)}{\mathrm{d} t^{n}}+a_{1} \frac{\mathrm{d}^{n-1} y(t)}{\mathrm{d} t^{n-1}}+\cdots+a_{n} y(t)=b_{0} \frac{\mathrm{d}^{m} u(t)}{\mathrm{d} t^{m}}+\cdots+b_{m} u(t)+v(t)
\end{equation}
$\frac{d^{i} x(t)}{d t^{i}}$代表信号$x(t)$对时间的 阶导数，该式表示了在任一时刻系统状态对时间的各阶导数与输入量对时间的各阶导数之间存在线性关系。对上式进行简化，仅考虑状态的最高一阶导数与输入量的零阶导数，并引入非线性成分，得到：
\begin{equation}
\dot {\boldsymbol y(t)}=f(\boldsymbol y(t), \boldsymbol{u}(t))
\end{equation}
其中 为某一未知函数且具有较强的非线性特性，相比于线性系统没有通用的非线性系统参数识别方法。神经网络近似能力的通用性可以作为建模非线性系统的一种手段\cite{funahashi1993approximation}。利用神经网路的前向传播过程模型系统动态过程\cite{temeng1995model, tan1996nonlinear}。
然而此类方法的缺陷的只能提供有限步，且一般情况是单步的预测，而无法起到系统识别与仿真的作用。循环神经网络（Recurrent neural network, RNN）因为存在隐状态，可以更好地处理长期预测问题并对系统进行建模\cite{delgado1995dynamic, zamarreno1998state}。
处理连续时间系统识别问题时，一个典型的困难是采样间隔分布不一致的问题。一种针对线性系统的传统解决方案是利用状态变量滤波方法，该方法可以近似给出各采样点对时间的各阶导数。非线性情形下，Demeester等\cite{demeester2020system}采用时间变化的神经序列模型解决该问题。

\subsection{基于编解码结构的系统预测}
当系统具有较大时延，即高时滞特性下，模型需要考虑历史数据对未来系统变化的影响。Felipe 等\cite{demeester2020system}利用带有Attention组件的Encoder-Decoder模型对一种名为膏体浓密机系统进行建模识别，Yuan等\cite{Yuan2020}采用一种更复杂的名为双注意力循环神经网络（Dual Attention Recurrent Neural Network， DARNN）的RNN网络对工业系统进行建模，两种方法都考虑了系统变量之间的长期依赖性，利用循环神经网络加Attention机制的强大编码能力，对历史数据、不同维度数据进行信息编码，来辅助输出量的预测，并且利用预测误差对编码器部分进行训练调整。然而两种方法都是针对离散时间系统设计的，不适用于连续时间系统建模问题。
\section{深度微分方程网络}
% \subsection{深度微分方程网络总描述}
% \subsection{微分方程网络概述}
发表自Nip2018的一篇开创性文章\cite{chen2018neural}提出了一种常微分方程神经网络，该网络可以模拟常微分的计算过程，并且给出了一种内存复杂度为常数量级的网络训练方法，网络参数的梯度求解等价于求解另一个常微分方程。
ODE-Net的主要应用包括Res-Net的替代、时间序列建模以及可逆正则化流\cite{Grathwohl2019}。本文主要围绕ODE-Net在时间序列建模中的应用展开研究。
因为ODE-Net的连续时间特性，该方法能够将深度网络模型应用于连续时间域下的时间序列建模问题研究中，开辟了时间序列分析、连续时间系统建模研究的新思路。
接下来本节将简单介绍几种常见的微分方程网络及其应用。
\subsection{常微分方程网络}
Chen等最早提出常微分方程网络化\cite{chen2018neural}开创了深度学习与微分方程结合的先河。
为了加速ODE-Net的求解，
Zhuang等\cite{Zhuang2020}提出了自适应检查点联合状态方法以改进原始adjont方法求解梯度的精度以及效率。正则化神经常微分方程（regularized neural ODE，RN-ODE）\cite{J2020}基于理论保证的最优传输和稳定性正则化简化ODE系统，能够有效优化ODE-Net的数值积分求解效率。
除此之外，对ODE方程的高阶导数正则化\cite{kelly2020}对求解时间点添加随机扰动\cite{Ghosh2020}等方案也能够起到正则化作用，加速ODE-Net的求解效率。

在处理时间序列问题时，相比于RNN等离散时间步下的循环神经网络。ODE-Net天然地适用于建模非均匀采样的时间序列。如基于ODE-Net衍生的ODE-RNN\cite{10.5555/3454287.3454765}、GRU-ODE-Bayes\cite{brouwer2019gru}、ODE-LSTM\cite{lechner2020learning}。
为了求解ODE-Net的初值，Latent ODE\cite{10.5555/3454287.3454765}将ODE-Net的初始状态视为先验分布为标准高斯分布的因变量，利用编码器-解码器结构实现序列的重构、插值、预测，并使用变分贝叶斯方法对模型进行训练。

文献\cite{Yildiz2019}基于贝叶斯理论，构建了2阶ODE-Net模型用于高维时间序列的建模，同时利用ODE-Net连续正则化流的特性估计待预测时间点隐变量的后验分布并引入分布正则化对隐状态的范围作出限定。

\subsection{受控微分方程网络}
由于常微分方程的解仅由初始状态决定，无法基于后续的观测对轨迹进行调节，使得诸如latent-ode、ODE2VAE等模型将序列观测信息全部压缩至初始状态中，有可能造成观测信息的信息损失。
神经受控微分方程（Neural Controlled Differential Equation）\cite{kidger2020neural}将受控信号的微分项融入在ODE网络的求解中。相比于在求解时间区间的间隔点处利用观测数据对隐状态进行更新的方法（如ODE-RNN、ODE-LSTM等），获得了更好的序列信息提取与表示能力。
为了解决神经受控微分方程在长时间序列场景下难以训练的问题，基于对数签名变换（Log signature transform）的Log-signature/NCDE方法\cite{morrill2021neural}通过签名变换对受控信号进行转换，能够增加模型训练速度、减少存储开销、改进模型预测性能。
针对常规的受控微分方程需要对离散序列进行样条插值，无法实现在线预测的情况，Morrill等\cite{morrill2021online}描述了受控微分方程中连续控制信号应满足的性质，并给出了三次埃尔米特直线插值方法，使受控微分方程网络能够类似于RNN一样，实现在线的时间序列数据处理，而不需要预先对完整的序列数据进行插值。
\subsection{随机微分方程网络}
随机微分方程相比于常微分方程项添加了扩散项。
对于随机微分方程的训练也可以采用联合敏感度法（Adjoint Sensitibity）进行训练\cite{li2020scalable}。由于随机微分方程网络的前向传播过程依赖于带有随机性的Wiener过程，为了避免存储完整的计算图，需要保证反向求解SDE时对Wiener过程的采样与前向传播保持一致。文献\cite{li2020scalable}利用基于虚拟布朗树（Virtual Brownian Tree）的伪随机数生成策略，仅需常数级存储$\mathcal{O}(1)$即可对的SDE网络前向传播的Wiener过程采样结果进行存储。节约存储空间的代价为对特定时间点下的wiener过程采样时间复杂度为$\mathcal{O}(\log n)$。
将微分方程网络作为Res-Net的替代品处理图像领域问题时，有研究表明将ODE-Net替代为SDE-Net，在ODE-Net中增加随机扩散项，也能够起到随机正则化的作用，提升网络的泛化能力\cite{Oganesyan2020}。
神经跳变随机微分方程（Neural Jump Stochastic Differential Equations，NJSDE）\cite{Jia2019}将扩散项中对时间的微分替换为观测点次数的微分，能够在建模系统隐空间连续时间动态的同时对观测点出现事件本身以及时刻进行建模，该模型有效地应用于地震预测及药物预测。

% \subsection{受控微分方程网络}
\section{深度微分方程网络的应用}
% \subsection{}
ODE-Net作为Res-Net的替代，可以应用于图像处理问题中：如图像超分问题\cite{OISR,jia2019focnet}。

在系统辨识领域，
Zhong等\cite{zhong2019symplectic}采用ODE-Net对符合哈密尔顿特性的动态系统进行建模学习，巧妙地将物理先验知识融入到学习模型的设计中。并有效地应用于符合哈密尔顿性质的刚体系统建模与控制问题中。
Ayed等\cite{ayed2019learning}采用ODE-Net模型从系统状态的部分可观测信息学习复杂非线性时空过程。该方法有效应用于水流动预测、Navier Stokes方程、海洋温度分析。
SNODE\cite{Quaglino2019}模型基于勒让德多项式构建ODE-Nets的压缩表示并应用于系统辨识。

为了建模来自于多智能体系统的非均匀采样数据，LG-ODE模型\cite{Huang2020}将图神经网络、自注意力以及ODE-Net进行结合，利用时序自注意力模型构建微分方程求解的初态，采用图神经网络建模观测点的时序依赖关系和不同观测项之间的空间依赖关系，并以此为基础估计常微分方程中的隐状态导数。模型有效地应用于稀疏序列的插值预测与外推预测。


对于Transformer、AttentionSeq2Seq等基于注意力的序列处理模型，利用ODE-Net的连续时间特性可以构建连续时间注意力模型\cite{chen2021continuous}，并将注意力机制应用于非均匀采样的时间序列。
近年来，Transformer模型\cite{Vaswani2017}因在序列数据处理问题上的优异表现受到了学者的广泛关注，基于Transformer的长序列预测模型，如Informer\cite{Zhou2020}、Autoformer\cite{Wu2021}等均获得比传统时序预测算法更优的预测精度。
得益于ODE-Net的连续时间特性，该模型能够与Transformer进行结合，处理非均匀采样数据或长序列预测及建模问题，如构建连续时间注意力\cite{chen2021continuous}、辅助位置编码（position embedding）\cite{Liu2020}。

ODE-Net模型能够利用非均匀采样数据拟合动态系统，因此可用于有模型强化学习\cite{Yildiz2021}领域，构建可微分的系统状态演化估计器，进而辅助策略模块的学习。
对于系统动态已知的连续时间系统，利用ODE-Net可以为策略网络构建连续时间梯度估计器\cite{Ainsworth2020}，使控制和仿真任务的学习更高效、更鲁棒。



