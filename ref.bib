% !Mode:: "TeX:UTF-8"

@book{oetiker2002,
   author = {Oetiker, Tobias and 中国CTEX用户小组},
   title = {一份不太简短的LATEX介绍},
   year = {2002},
   type = {Book}
}
@article{chenweide2009,
   author = {陈德伟},
   title = {用LaTeX撰写学位论文},
   journal = {软件导刊},
   number = {11},
   pages = {100-102},
   abstract = {学位论文作为高校教学计划中的重要环节,对提高教学质量、培养学生综合应用能力具有十分重要的意义。LaTeX是一种格式化的排版系统,将它应用于学位论文的撰写,真正做到编辑、排版、校对一体化,在较高层次上实现学位论文排版的美感。讨论了如何采用LaTeX系统来撰写学位论文。如果将此作为学位论文模板共享将大大节省学位论文的排版时间,提高高校学位论文规范化管理的质量。},
   keywords = {LaTeX系统
学位论文
科技排版},
   ISSN = {1672-7800},
   year = {2009},
   type = {Journal Article}
}

@article{duanmaiying2003,
   author = {段麦英},
   title = {英文科技论文的LaTeX排版},
   journal = {雁北师范学院学报},
   number = {02},
   pages = {22-24},
   abstract = {LaTeX是普遍采用的通用英文科技出版物排版软件之一 ,国际英文物理学期刊无一例外都接受LaTeX格式的文稿 .在本文中 ,笔者结合自己使用LaTeX排版的一些经验 ,介绍了LaTeX排版软件基本命令的使用方法和技巧 .},
   keywords = {英文科技论文
LaTeX排版
方法和技巧},
   ISSN = {1009-1939},
   year = {2003},
   type = {Journal Article}
}

@article{jihongwei2011,
   author = {纪宏伟},
   title = {数学论文的LaTeX排版与全文上网},
   journal = {软件导刊(教育技术)},
   number = {01},
   pages = {87-88},
   abstract = {LaTeX是一种格式化的排版系统,将它应用于数学论文的排版,可在较高层次上实现数学论文排版的美感。介绍了LaTeX的排版过程及其排版功能,探讨了数学论文全文上网的实现手段,并提供了切实可行的简便方法。},
   keywords = {LaTeX
排版系统
PDF文档
数据库},
   ISSN = {1672-7800},
   year = {2011},
   type = {Journal Article}
}

@article{majiajia2014,
   author = {马加佳},
   title = {LaTeX与Word文件的相互转换},
   journal = {中国科技期刊研究},
   number = {03},
   pages = {378-382},
   abstract = {利用TeX2Word与Word2TeX软件,可以迅速实现Word与LaTeX文件的互相转换,使排版人员或作者在重新排版时减少工作量,提高排版效率。分别介绍这两款软件的使用方法,通过转换前后的效果对比,探讨Word与LaTeX文件互转的可行性及需要注意的问题。},
   keywords = {排版
LaTeX Word转换
TeX2Word Word2TeX},
   ISSN = {1001-7143},
   year = {2014},
   type = {Journal Article}
}

@article{niejun2010,
   author = {聂俊 and 陈天莹 and 符红光},
   title = {基于Latex的互联网数学公式搜索引擎},
   journal = {计算机应用},
   number = {S2},
   pages = {312-315},
   abstract = {互联网上数学公式的搜索对学习和科研非常重要,目前Google、百度等著名搜索引擎还没提供类似的服务。除图片外,数学公式在互联网上主要以Latex和MathML的形式存在。对这两种数学公式格式,至今仍未出现成熟的数学公式搜索引擎。以Latex格式为基础(MathML可转为Latex格式),提出数学公式的分词、索引和匹配算法,并在开源的Lucene平台上实现了一个高效的数学公式搜索引擎。},
   keywords = {数学公式
搜索引擎
Latex
MathML},
   ISSN = {1001-9081},
   year = {2010},
   type = {Journal Article}
}

@article{wangyong2012,
   author = {王勇 and 姚萍 and 王岚 and 庞立},
   title = {LaTeX与方正书版排版数学论文探讨},
   journal = {中国科技期刊研究},
   number = {06},
   pages = {1036-1039},
   abstract = {从获取渠道、排版程序、排版效果、排版命令以及最终文稿等方面分析比较了LaTeX和方正书版2种软件排版数学论文的特点。比较发现,在排版数学论文方面,LaTeX软件更有优势。},
   keywords = {LaTeX
方正书版
数学论文},
   ISSN = {1001-7143},
   year = {2012},
   type = {Journal Article}
}

@article{wenyayuan2012,
   author = {温亚媛 and 赵景芝 and 李向华 and 谢冰蓉},
   title = {LaTeX排版系统在英文学术期刊中的应用},
   journal = {中国科技期刊研究},
   number = {05},
   pages = {825-830},
   abstract = {结合英文学术期刊使用LaTeX排版系统的工作经验,总结出一些使用该系统排版的心得体会。分析整理作者来稿中经常出现的问题,给出了解决的办法。同时给出我们在日常编辑工作中常用的宏包和模板,以及一些排版小技巧,与编辑同行交流。希望能对LaTeX初学者及正在使用LaTeX撰写论文的年轻作者有所帮助。},
   keywords = {LaTeX
排版
技巧
方法},
   ISSN = {1001-7143},
   year = {2012},
   type = {Journal Article}
}
@inproceedings{lutter2019deep,
  title={Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning},
  author={Lutter, M and Ritter, C and Peters, Jan},
  booktitle={International Conference on Learning Representations (ICLR 2019)},
  year={2019},
  organization={OpenReview. net}
}

@online{gupta2019general,
  title={A general framework for structured learning of mechanical systems},
  author={Gupta, Jayesh K and Menda, Kunal and Manchester, Zachary and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:1902.08705},
  url={https://arxiv.org/abs/1902.08705},
  doi={,},
  year={2019}
}

@inproceedings{sanchez2018graph,
  title={Graph networks as learnable physics engines for inference and control},
  author={Sanchez-Gonzalez, Alvaro and Heess, Nicolas and Springenberg, Jost Tobias and Merel, Josh and Riedmiller, Martin and Hadsell, Raia and Battaglia, Peter},
  booktitle={International Conference on Machine Learning},
  pages={4470--4479},
  year={2018},
  organization={PMLR}
}

@article{greydanus2019hamiltonian,
  title={Hamiltonian Neural Networks},
  author={Greydanus, Samuel and Dzamba, Misko and Yosinski, Jason},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15379--15389},
  year={2019}
}

@book{box2015time,
  title={Time series analysis: forecasting and control},
  author={Box, George EP and Jenkins, Gwilym M and Reinsel, Gregory C and Ljung, Greta M},
  year={2015},
  publisher={John Wiley \& Sons}
}

@article{benjamin2003generalized,
  title={Generalized autoregressive moving average models},
  author={Benjamin, Michael A and Rigby, Robert A and Stasinopoulos, D Mikis},
  journal={Journal of the American Statistical association},
  volume={98},
  number={461},
  pages={214--223},
  year={2003},
  publisher={Taylor \& Francis}
}

@article{zhang2021DLgeneral,
author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
title = {Understanding Deep Learning (Still) Requires Rethinking Generalization},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {3},
issn = {0001-0782},
journal = {Commun. ACM},
month = feb,
pages = {107–115},
numpages = {9}
}

@article{karpatne2017theory,
  title={Theory-guided data science: A new paradigm for scientific discovery from data},
  author={Karpatne, Anuj and Atluri, Gowtham and Faghmous, James H and Steinbach, Michael and Banerjee, Arindam and Ganguly, Auroop and Shekhar, Shashi and Samatova, Nagiza and Kumar, Vipin},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={29},
  number={10},
  pages={2318--2331},
  year={2017},
  publisher={IEEE}
}

@inproceedings{doan2019physics,
  title={Physics-informed echo state networks for chaotic systems forecasting},
  author={Doan, Nguyen Anh Khoa and Polifke, Wolfgang and Magri, Luca},
  booktitle={International Conference on Computational Science},
  pages={192--198},
  year={2019},
  organization={Springer}
}

@inproceedings{baseman2018physics,
  title={Physics-informed machine learning for DRAM error modeling},
  author={Baseman, Elisabeth and DeBardeleben, Nathan and Blanchard, Sean and Moore, Juston and Tkachenko, Olena and Ferreira, Kurt and Siddiqua, Taniya and Sridharan, Vilas},
  booktitle={2018 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{park2019physics,
  title={Physics-induced graph neural network: An application to wind-farm power estimation},
  author={Park, Junyoung and Park, Jinkyoo},
  journal={Energy},
  volume={187},
  pages={115883},
  year={2019},
  publisher={Elsevier}
}

@article{lagergren2020learning,
  title={Learning partial differential equations for biological transport models from noisy spatio-temporal data},
  author={Lagergren, John H and Nardini, John T and Michael Lavigne, G and Rutter, Erica M and Flores, Kevin B},
  journal={Proceedings of the Royal Society A},
  volume={476},
  number={2234},
  pages={20190800},
  year={2020},
  publisher={The Royal Society Publishing}
}

@article{schmidt2009distilling,
  title={Distilling free-form natural laws from experimental data},
  author={Schmidt, Michael and Lipson, Hod},
  journal={science},
  volume={324},
  number={5923},
  pages={81--85},
  year={2009},
  publisher={American Association for the Advancement of Science}
}

@online{yang2018physics,
  title={Physics-informed deep generative models},
  author={Yang, Yibo and Perdikaris, Paris},
  journal={arXiv preprint arXiv:1812.03511},
  doi={,},
  url={https://arxiv.org/abs/1812.03511},
  year={2018}
}

@article{raissi2018deep,
  title={Deep hidden physics models: Deep learning of nonlinear partial differential equations},
  author={Raissi, Maziar},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={932--955},
  year={2018},
  publisher={JMLR. org}
}

@article{ZHU201956,
title = {Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data},
journal = {Journal of Computational Physics},
volume = {394},
pages = {56-81},
year = {2019},
issn = {0021-9991},
author = {Yinhao Zhu and Nicholas Zabaras and Phaedon-Stelios Koutsourelakis and Paris Perdikaris},
}

@article{RAISSI2019686,
title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
journal = {Journal of Computational Physics},
volume = {378},
pages = {686-707},
year = {2019},
issn = {0021-9991},
author = {M. Raissi and P. Perdikaris and G.E. Karniadakis},
}

@article{weinan2017proposal,
  title={A proposal on machine learning via dynamical systems},
  author={Weinan, E},
  journal={Communications in Mathematics and Statistics},
  volume={5},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Springer}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={6572--6583},
  year={2018}
}

@inproceedings{kidger2020neural,
 author = {Patrick Kidger and
James Morrill and
James Foster and
Terry J. Lyons},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/KidgerMFL20.bib},
 booktitle = {NeurIPS 2020, December
6-12, 2020, virtual},
 title = {Neural Controlled Differential Equations for Irregular Time Series},
 year = {2020}
}


@inproceedings{brouwer2019gru,
  title={GRU-ODE-Bayes: continuous modeling of sporadically-observed time series},
  author={Brouwer, Edward De and Simm, Jaak and Arany, Adam and Moreau, Yves},
  booktitle={Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  pages={7379--7390},
  year={2019}
}

@article{jordan2021gated,
  title={Gated recurrent units viewed through the lens of continuous time dynamical systems},
  author={Jordan, Ian D and Sok{\'o}{\l}, Piotr Aleksander and Park, Il Memming},
  journal={Frontiers in computational neuroscience},
  pages={67},
  year={2021},
  publisher={Frontiers}
}
@article{zhang2019anodev2,
  title={ANODEV2: A coupled neural ODE framework},
  author={Zhang, Tianjun and Yao, Zhewei and Gholami, Amir and Gonzalez, Joseph E and Keutzer, Kurt and Mahoney, Michael W and Biros, George},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={5151--5161},
  year={2019}
}


@INPROCEEDINGS{SeducePastor2018, 
author={J. {Pastor} and J. M. {Menaud}}, 
booktitle={Proceedings of the 26th International Conference on Software, Telecommunications and Computer Networks (SoftCOM2018)}, 
title={SeDuCe: a Testbed for Research on Thermal and Power Management in Datacenters}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-6}, 
ISSN={1847-358X}, 
month={Sep.},
}

@incollection{grid5000,
   title = {Adding Virtualization Capabilities to the {Grid'5000} Testbed},
   author = {Balouek, Daniel and Carpen Amarie, Alexandra and Charrier, Ghislain and Desprez, Fr{\'e}d{\'e}ric and Jeannot, Emmanuel and Jeanvoine, Emmanuel and L{\`e}bre, Adrien and Margery, David and Niclausse, Nicolas and Nussbaum, Lucas and Richard, Olivier and P{\'e}rez, Christian and Quesnel, Flavien and Rohr, Cyril and Sarzyniec, Luc},
   booktitle = {Cloud Computing and Services Science},
   publisher = {Springer International Publishing},
   pages = {3-20},
   volume = {367},
   editor = {Ivanov, Ivan I. and van Sinderen, Marten and Leymann, Frank and Shan, Tony },
   series = {Communications in Computer and Information Science },
   isbn = {978-3-319-04518-4 },
   year = {2013},
}

@misc{InrowACRD602,
  title={InRow Direct Expansion (ACRD602)},
  author={{Schneider Electric}},
  year={2019},
  note={accessed: December 15,2019}
}

@article{alonso2020estimating,
  title={Estimating cooling production and monitoring efficiency in chillers using a soft sensor},
  author={Alonso, Seraf{\'\i}n and Mor{\'a}n, Antonio and P{\'e}rez, Daniel and Prada, Miguel A and Diaz, Ignacio and Dom{\'\i}nguez, Manuel},
  journal={Neural Computing and Applications},
  volume={32},
  number={23},
  pages={17291--17308},
  year={2020},
  publisher={Springer}
}

@techreport{ashraeTC992011,
  title={2011 Thermal Guidelines for Data Processing Environments – Expanded Data Center Classes and Usage Guidance},
  author={ASHRAE Technical Committee},
  year={2011},
  institution={ASHRAE},
}

@article{hopcroft2001introduction,
  title={Introduction to automata theory, languages, and computation},
  author={Hopcroft, John E and Motwani, Rajeev and Ullman, Jeffrey D},
  journal={Acm Sigact News},
  volume={32},
  number={1},
  pages={60--65},
  year={2001},
  publisher={ACM New York, NY, USA}
}

@article{Deep_state_space_model,
abstract = {We present a novel approach to probabilistic time series forecasting that combines state space models with deep learning. By parametrizing a per-time-series linear state space model with a jointly-learned recurrent neural network, our method retains desired properties of state space models such as data efficiency and inter-pretability, while making use of the ability to learn complex patterns from raw data offered by deep learning approaches. Our method scales gracefully from regimes where little training data is available to regimes where data from large collection of time series can be leveraged to learn accurate models. We provide qualitative as well as quantitative results with the proposed method, showing that it compares favorably to the state-of-the-art.},
author = {Deep state space models for time series forecastingRangapuram, Syama Sundar and Seeger, Matthias and Gasthaus, Jan and Stella, Lorenzo and Wang, Yuyang and Januschowski, Tim},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Paper 4852$\backslash$$\backslash$deep-state-long-version.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {7785--7794},
title = {{Deep state space models for time series forecasting}},
volume = {2018-Decem},
year = {2018}
}


@inproceedings{Fraccaro2017,
	author = {Fraccaro, Marco and Kamronn, Simon and Paquet, Ulrich and Winther, Ole},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning},
	url = {https://proceedings.neurips.cc/paper/2017/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf},
	volume = {30},
	year = {2017},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2017/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf}}



@inproceedings{Knauf2018,
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Neural Ordinary Differential Equations},
	url = {https://proceedings.neurips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf},
	volume = {31},
	year = {2018},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf}}


@article{nason2006stationary,
  title={Stationary and non-stationary time series},
  author={Nason, Guy P},
  journal={Statistics in volcanology},
  volume={60},
  year={2006},
  publisher={Geological Society of London, London}
}
@inproceedings{Demeester2019,
  title={System identification with time-aware neural sequence models},
  author={Demeester, Thomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3757--3764},
  year={2020}
}
@inbook{10.5555/3454287.3454765,
author = {Rubanova, Yulia and Chen, Ricky T. Q. and Duvenaud, David},
title = {Latent ODEs for Irregularly-Sampled Time Series},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Time series with non-uniform intervals occur in many applications, and are difficult
to model using standard recurrent neural networks (RNNs). We generalize RNNs to have
continuous-time hidden dynamics defined by ordinary differential equations (ODEs),
a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition
network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can
naturally handle arbitrary time gaps between observations, and can explicitly model
the probability of observation times using Poisson processes. We show experimentally
that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled
data.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {478},
numpages = {11}
}
@inproceedings{Hafner2019,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{yuan2020dual,
  title={A dual-attention recurrent neural network method for deep cone thickener underflow concentration prediction},
  author={Yuan, Zhaolin and Hu, Jinlong and Wu, Di and Ban, Xiaojuan},
  journal={Sensors},
  volume={20},
  number={5},
  pages={1260},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@article{du2020multivariate,
  title={Multivariate time series forecasting via attention-based encoder--decoder framework},
  author={Du, Shengdong and Li, Tianrui and Yang, Yan and Horng, Shi-Jinn},
  journal={Neurocomputing},
  volume={388},
  pages={269--279},
  year={2020},
  publisher={Elsevier}
}
@inproceedings{li2016scalable,
  title={A scalable end-to-end Gaussian process adapter for irregularly sampled time series classification},
  author={Li, Steven Cheng-Xian and Marlin, Benjamin},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={1812--1820},
  year={2016}
}
@inproceedings{shukla2018interpolation,
  title={Interpolation-Prediction Networks for Irregularly Sampled Time Series},
  author={Shukla, Satya Narayan and Marlin, Benjamin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{Yildiz2019,
	author = {Yildiz, Cagatay and Heinonen, Markus and Lahdesmaki, Harri},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {ODE2VAE: Deep generative second order ODEs with Bayesian neural networks},
	volume = {32},
	year = {2019}
}
@article{WANG2013,
author = {WANG, Le-Yi and ZHAO, Wen-Xiao},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/wang2013.pdf:pdf},
issn = {18741029},
journal = {Acta Automatica Sinica},
keywords = {2013,39,7,933,942,System identification,acta automatica,and opportunities,challenges,citation wang le-yi,complexity,identification and decision,information,integration of,integration of identification and decision,large data processing,networked system,new paradigms,sinica,system identification,uncertainty,zhao wen-xiao},
mendeley-groups = {system{\_}identify},
number = {7},
pages = {933--942},
publisher = {The Chinese Association of Automation and The Institute of Automation, Chinese Academy of Sciences},
title = {{System Identification: New Paradigms, Challenges, and Opportunities}},
volume = {39},
year = {2013}
}

@ARTICLE{9260162,
  author={Liu, Haoyue and Chatterjee, Ishani and Zhou, MengChu and Lu, Xiaoyu Sean and Abusorrah, Abdullah},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Aspect-Based Sentiment Analysis: A Survey of Deep Learning Methods}, 
  year={2020},
  volume={7},
  number={6},
  pages={1358-1375},
  }
  
@ARTICLE{9161367,
  author={Liu, Jin and Wu, NaiQi and Qiao, Yan and Li, ZhiWu},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Short-Term Traffic Flow Forecasting Using Ensemble Approach Based on Deep Belief Networks}, 
  year={2020},
  volume={},
  number={},
  pages={1-14}
  }
  
@ARTICLE{9326384,
  author={Li, Huifang and Hu, Guangzheng and Li, Jianqiang and Zhou, Mengchu},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Intelligent Fault Diagnosis for Large-Scale Rotating Machines Using Binarized Deep Neural Networks and Random Forests}, 
  year={2021},
  volume={},
  number={},
  pages={1-11}
  }

@article{Essien2020,
author = {Essien, Aniekan Emmanuel and Giannetti, Cinzia},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/A{\_}Deep{\_}Learning{\_}model{\_}for{\_}Smart{\_}Manufacturing{\_}usin.pdf:pdf},
issn = {1551-3203},
journal = {IEEE Transactions on Industrial Informatics},
mendeley-groups = {time series},
volume={16},
number={9},
pages={6069--6078},
title = {{A Deep Learning model for Smart Manufacturing using Convolutional LSTM Neural Network Autoencoders}},
year = {2020}
}
@ARTICLE{4019326,
  author={M. {GEVERS}},
  journal={IEEE Control Systems Magazine}, 
  title={A personal view of the development of system identification: A 30-year journey through an exciting field}, 
  year={2006},
  volume={26},
  number={6},
  pages={93-105},
}
@article{Wang1998,
abstract = {This paper proposes the Runge-Kutta neural networks (RKNN's) for identification of unknown dynamical systems described by ordinary differential equations (i.e., ordinary differential equation or ODE systems) in high accuracy. These networks are constructed according to the Runge-Kutta approximation method. The main attraction of the RKNN's is that they precisely estimate the changing rates of system states (i.e., the right-hand side of the ODE x = f(x)) directly in their subnetworks based on the space-domain interpolation within one sampling interval such that they can do long-term prediction of system state trajectories. We show theoretically the superior generalization and long-term prediction capability of the RKNN's over the normal neural networks. Two types of learning algorithms are investigated for the RKNN's, gradient-and nonlinear recursive least-squares-based algorithms. Convergence analysis of the learning algorithms is done theoretically. Computer simulations demonstrate the proved properties of the RKNN's. {\textcopyright} 1998 IEEE.},
author = {Wang, Yi Jen and Lin, Chin Teng},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/yi-jenwang1998.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Contraction mapping,Gradient descent,Nonlinear recursive least square,Radial-basis function,Runge-Kutta method,Vander Pol's equation},
mendeley-groups = {system{\_}identify},
number = {2},
pages = {294--307},
title = {{Runge-Kutta neural network for identification of dynamical systems in high accuracy}},
volume = {9},
year = {1998}
}
@article{Weiss2017Sequence,
  title={Sequence-to-Sequence Models Can Directly Translate Foreign Speech},
  author={Weiss, Ron J and Chorowski, Jan and Jaitly, Navdeep and Wu, Yonghui and Chen, Zhifeng},
  journal={Proc. Interspeech 2017},
  pages={2625--2629},
  year={2017}
}
@article{Cho2014Learning,
  title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation},
  author={Cho, Kyunghyun and Van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={Computer Science},
  year={2014},
}
@inproceedings{Demeester2020SystemIW,
  title={System identification with time-aware neural sequence models},
  author={Demeester, Thomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3757--3764},
  year={2020}
}
@article{CHAI201661,
  title={An intelligent switching control for a mixed separation thickener process},
  author={Chai, Tianyou and Jia, Yao and Li, Haibo and Wang, Hong},
  journal={Control Engineering Practice},
  volume={57},
  pages={61--71},
  year={2016},
  publisher={Elsevier}
}
@article{KIM2004403,
  title={Development and application of a dynamic model for hindered-settling column separations},
  author={Kim, BH and Klima, Mark Stephen},
  journal={Minerals engineering},
  volume={17},
  number={3},
  pages={403--410},
  year={2004},
  publisher={Elsevier}
}
@incollection{NIPS2018_7892,
title = {Neural Ordinary Differential Equations},
author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {6571--6583},
year = {2018},
publisher = {Curran Associates, Inc.},
}
@inproceedings{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={ICLR (Poster)},
  year={2015}
}
@article{Botchkarev2019,
abstract = {Aim/Purpose The aim of this study was to analyze various performance metrics and approaches to their classification. The main goal of the study was to develop a new typology that will help to advance knowledge of metrics and facilitate their use in machine learning regression algorithms Background Performance metrics (error measures) are vital components of the evaluation frameworks in various fields. A performance metric can be defined as a logical and mathematical construct designed to measure how close are the actual results from what has been expected or predicted. A vast variety of performance metrics have been described in academic literature. The most commonly mentioned metrics in research studies are Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), etc. Knowledge about metrics properties needs to be systematized to simplify the design and use of the metrics. Methodology A qualitative study was conducted to achieve the objectives of identifying related peer-reviewed research studies, literature reviews, critical thinking and inductive reasoning. Contribution The main contribution of this paper is in ordering knowledge of performance metrics and enhancing understanding of their structure and properties by proposing a new typology, generic primary metrics mathematical formula and a visualization chart Findings Based on the analysis of the structure of numerous performance metrics, we proposed a framework of metrics which includes four (4) categories: primary metrics, extended metrics, composite metrics, and hybrid sets of metrics. The paper identified three (3) key components (dimensions) that determine the structure and properties of primary metrics: method of determining point distance, method of normalization, method of aggregation of point distances over a data set. For each component, implementation options have been identified. The suggested new typology has been shown to cover a total of over 40 commonly used primary metrics Recommendations Presented findings can be used to facilitate teaching performance metrics to for Practitioners university students and expedite metrics selection and implementation processes for practitioners Recommendations By using the proposed typology, researchers can streamline development of for Researchers new metrics with predetermined properties Impact on Society The outcomes of this study could be used for improving evaluation results in machine learning regression, forecasting and prognostics with direct or indirect positive impacts on innovation and productivity in a societal sense Future Research Future research is needed to examine the properties of the extended metrics, composite metrics, and hybrid sets of metrics. Empirical study of the metrics is needed using R Studio or Azure Machine Learning Studio, to find associations between the properties of primary metrics and their “numerical” behavior in a wide spectrum of data characteristics and business or research requirements.},
author = {Botchkarev, Alexei},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/IJIKMv14p045-076Botchkarev5064.pdf:pdf},
issn = {15551237},
journal = {Interdisciplinary Journal of Information, Knowledge, and Management},
keywords = {Accuracy measures,Classification,Dissimilarity,Distance,Error measures,Estimation,Evaluation,Forecasting,Machine learning,Modeling,Performance metrics,Prediction,Prognostics,Properties,Regression,Similarity,Typology},
mendeley-groups = {Regression metrics},
number = {January},
pages = {45--76},
title = {{A new typology design of performance metrics to measure errors in machine learning regression algorithms}},
volume = {14},
year = {2019}
}
@article{hongjiang2011study,
  title={Study on the thickening properties of unclassified tailings and its application to thickener design},
  author={Hongjiang, Wang and Qinrui, Chen and Aixiang, Wu and others},
  journal={Journal of University of Science and Technology Beijing},
  volume={6},
  pages={676--681},
  year={2011}
}

@inproceedings{Kratochwil1997A,
  title={A simple algorithm for asymptotically optimal reduced-state sequence estimation},
  author={Kratochwil, Konrad},
  booktitle={Proceedings of ICUPC 97-6th International Conference on Universal Personal Communications},
  volume={2},
  pages={718--722},
  year={1997},
  organization={IEEE}
}
@inproceedings{bahdanau2014neural,
author = {Dzmitry Bahdanau and
Kyunghyun Cho and
Yoshua Bengio},
bibsource = {dblp computer science bibliography, https://dblp.org},
booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
 editor = {Yoshua Bengio and
Yann LeCun},
 timestamp = {Fri, 29 Mar 2019 00:00:00 +0100},
 title = {Neural Machine Translation by Jointly Learning to Align and Translate},
 year = {2015}
}
@inproceedings{Merri2014,
 address = {Doha, Qatar},
 author = {Cho, Kyunghyun  and
van Merri{\"e}nboer, Bart  and
Bahdanau, Dzmitry  and
Bengio, Yoshua},
 booktitle = {Proceedings of {SSST}-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation},
 pages = {103--111},
 publisher = {Association for Computational Linguistics},
 title = {On the Properties of Neural Machine Translation: Encoder{--}Decoder Approaches},
 year = {2014}
}

@article{Zhang2018_02,
  title={Residual dense network for image restoration},
  author={Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}
@inproceedings{Huang2017,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}


@inproceedings{contextaware,
author = {Zhou, Yang and Huang, Yan},
year = {2018},
month = {12},
pages = {2393-2402},
title = {Context Aware Flow Prediction of Bike Sharing Systems},
}
@article{HuangAn2014,
  title={An Insight into Extreme Learning Machines: Random Neurons, Random Features and Kernels},
  author={Huang and Guang-Bin},
  journal={Cognitive Computation 2014},
  volume={6},
  number={3},
  pages={376-390},
}
@article{Ke2017,
abstract = {Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: Gradient-based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB LightGBM. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy.},
author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie Yan},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {machine learning},
number = {Nips},
pages = {3146--3154},
title = {{LightGBM: A highly efficient gradient boosting decision tree}},
volume = {2017-December},
year = {2017}
}
@inproceedings{Wu:2019:CAC:3357384.3358133,
 author = {Wu, Di and Wang, Hao and Seidu, Razak},
 title = {Collaborative Analysis for Computational Risk in Urban Water Supply Systems},
 booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
 series = {CIKM '19},
 year = {2019},
 isbn = {978-1-4503-6976-3},
 location = {Beijing, China},
 pages = {2297--2300},
 numpages = {4},
 acmid = {3358133},
 keywords = {collaborative analysis, computational risk, structural similarity, urban water supply, water quality control},
} 
@ARTICLE{wu2019_2,
author={D. {Wu} and H. {Wang} and H. {Mohammed} and R. {Seidu}},
journal={IEEE Transactions on Sustainable Computing},
title={Quality Risk Analysis for Sustainable Smart Water Supply Using Data Perception},
year={2019},
volume={},
number={},
pages={1-1},
keywords={Sustainable Water Supply;Water Quality Control;Data Perception;Risk Evaluation;Frequency Analysis;Scalability},
ISSN={2377-3790},
month={},}

@article{Zhou:2019:LCN:3368406.3339308,
  title={Lightweight convolution neural networks for mobile edge computing in transportation cyber physical systems},
  author={Zhou, Junhao and Dai, Hong-Ning and Wang, Hao},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={6},
  pages={1--20},
  year={2019},
  publisher={ACM New York, NY, USA}
} 
@article{Dai:2019:BDA:3362097.3337065,
 author = {Dai, Hong-Ning and Wong, Raymond Chi-Wing and Wang, Hao and Zheng, Zibin and Vasilakos, Athanasios V.},
 title = {Big Data Analytics for Large-scale Wireless Networks: Challenges and Opportunities},
 journal = {ACM Comput. Surv.},
 issue_date = {October 2019},
 volume = {52},
 number = {5},
 month = sep,
 year = {2019},
 issn = {0360-0300},
 pages = {99:1--99:36},
 articleno = {99},
 numpages = {36},
 acmid = {3337065},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Big data, machine learning, wireless networks},
} 
@article{Tan2017,
abstract = {As a separation process, a paste thickener produces underflow with a high solids concentration. Such underflow leads to a high rake torque which could cause serious operational problems such as underflow blockage, pumping problems and potential donut formation. In this work, a model predictive control approach has been developed to control the underflow solids concentration subject to operational constraints. State observers including linear and extended Kalman filters are studied to determine a cost-effective approach to estimating the solids concentration profile in the paste thickener, which is important for thickener control. A rake torque model is validated with industrial plant data. By utilising the monotonic property of the rake torque model, a linear model predictive control (MPC) approach is developed to deal with the nonlinear constrained control problem. Using an industrial paste thickener as a case study, simulation results demonstrates that the proposed control approach, including an extended Kalman filter, can effectively regulate the underflow solids concentration within permissible operating windows, preventing rake lifting and pumping problems.},
author = {Tan, Chee Keong and Bao, Jie and Bickert, G{\"{o}}tz},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S0892687517300213-main.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Kalman filter,Model predictive control,Rake torque,Rheology,Sedimentation-consolidation model},
mendeley-groups = {pastethickener},
pages = {52--62},
publisher = {Elsevier Ltd},
title = {{A study on model predictive control in paste thickeners with rake torque constraint}},
volume = {105},
year = {2017}
}

@incollection{jeschke2017erratum,
  title={Erratum to: Industrial Internet of Things},
  author={Jeschke, Sabina and Brecher, Christian and Song, Houbing and Rawat, Danda B},
  booktitle={Industrial Internet of Things},
  pages={E1--E1},
  year={2017},
  publisher={Springer}
}

@article{bangemann2016integration,
  title={Integration of classical components into industrial cyber--physical systems},
  author={Bangemann, Thomas and Riedl, Matthias and Thron, Mario and Diedrich, Christian},
  journal={Proceedings of the IEEE},
  volume={104},
  number={5},
  pages={947--959},
  year={2016},
  publisher={IEEE}
}
@ARTICLE{Broersen2000,
author={P. M. T. {Broersen}},
journal={IEEE Transactions on Signal Processing},
title={Autoregressive model orders for Durbin's MA and ARMA estimators},
year={2000},
volume={48},
number={8},
pages={2454-2457},
keywords={moving average processes;autoregressive moving average processes;parameter estimation;autoregressive processes;sampling methods;autoregressive model orders;moving average parameters;autoregressive-moving average parameters;Durbin's methods;MA parameters;ARMA parameters;parameter estimation;linear regression theory;sample size;predicting AR model;long AR model;Predictive models;Parameter estimation;Linear regression;Computational modeling;Yield estimation;Maximum likelihood estimation;Physics;Minimization methods;Poles and zeros;Estimation theory},
ISSN={1941-0476},
month={Aug},}
@article{VALIPOUR2013433,
title = "Comparison of the ARMA, ARIMA, and the autoregressive artificial neural network models in forecasting the monthly inflow of Dez dam reservoir",
journal = "Journal of Hydrology",
volume = "476",
pages = "433 - 441",
year = "2013",
issn = "0022-1694",
author = "Mohammad Valipour and Mohammad Ebrahim Banihabib and Seyyed Mahmood Reza Behbahani",
keywords = "ARIMA, ARMA, Autoregressive artificial neural network, Dez dam, Forecast of dam reservoir inflow",
abstract = "Summary
The goal of the present research is forecasting the inflow of Dez dam reservoir by using Auto Regressive Moving Average (ARMA) and Auto Regressive Integrated Moving Average (ARIMA) models while increasing the number of parameters in order to increase the forecast accuracy to four parameters and comparing them with the static and dynamic artificial neural networks. In this research, monthly discharges from 1960 to 2007 were used. The statistics related to first 42years were used to train the models and the 5 past years were used to forecast. In ARMA and ARIMA models, the polynomial was derived respectively with four and six parameters to forecast the inflow. In the artificial neural network, the radial and sigmoid activity functions were used with several different neurons in the hidden layers. By comparing root mean square error (RMSE) and mean bias error (MBE), dynamic artificial neural network model with sigmoid activity function and 17 neurons in the hidden layer was chosen as the best model for forecasting inflow of the Dez dam reservoir. Inflow of the dam reservoir in the 12 past months shows that ARIMA model had a less error compared with the ARMA model. Static and Dynamic autoregressive artificial neural networks with activity sigmoid function can forecast the inflow to the dam reservoirs from the past 60months."
}
@article{Oh2010,
abstract = {In this paper, we present a new morphology-based homomorphic filtering technique for feature enhancement in medical images. The proposed method is based on decomposing an image into morphological subbands. The homomorphic filtering is performed using the morphological subbands. The differential evolution algorithm is applied to find an optimal gain and structuring element for each subband. Simulations show that the proposed filter improves the contrast of the features in medical images. {\textcopyright} 2010 ICROS, KIEE and Springer.},
author = {Oh, Jinsung and Hwang, Heesoo},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/s12555-010-0418-y.pdf:pdf},
issn = {15986446},
journal = {International Journal of Control, Automation and Systems},
keywords = {Differential evolution algorithm,homomorphic filter,image enhancement,morphological filter},
mendeley-groups = {machine learning},
number = {4},
pages = {857--861},
title = {{Feature enhancement of medical images using morphology-based homomorphic filter and differential evolution algorithm}},
volume = {8},
year = {2010}
}
@article{Langlois2019,
abstract = {The purpose of this paper is to extend existing mathematical models of tailings rheology and sedimentation to form a complete dynamic simulator. It is complete in the sense that it includes all important rheological variables for the development of multivariable control strategies and can be integrated with other stages of tailings management systems. This work extends a one-dimensional model for the dynamics of a flocculated suspension in a clarifier-thickener to include the discharge yield stress and particle size distribution in a manner that is computationally tractable. The paper also extends a static yield stress model to include the effect of particle size distribution, in a manner that is consistent with previous empirical and theoretical evidence. The dynamic simulator is validated through the simulation of a Proportional-Integral control strategy and proves to be a useful and flexible tool for the development of control strategies.},
author = {Langlois, Juan I. and Cipriano, Aldo},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S0892687518304771-main.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Dynamic simulation,Flocculation,Numerical simulation,Particle size distribution,Sedimentation-consolidation model,Yield stress},
mendeley-groups = {thickener},
pages = {131--139},
publisher = {Elsevier},
title = {{Dynamic modeling and simulation of tailing thickener units for the development of control strategies.}},
volume = {131},
year = {2019}
}
@article{Xiao2020,
abstract = {As a method for extracting metals and their compounds, hydrometallurgy has the advantages of high comprehensive metal recovery rate, low environmental pollution, and easier production process. The intensive washing process is a key process in the hydrometallurgical process, and the underflow concentration is a key indicator for measuring the quality of the concentrated washing process. In this paper, after analyzing the characteristics of the thick washing process, the hybrid model combining mechanism modeling and error compensation model based on EDO-TELM (three hidden layers Extreme Learning Machine optimized with Entire Distribution Optimization algorithm) is used to achieve accurate measurement of the underflow concentration in the dense washing process. The hybrid model uses the improved EDO-TELM algorithm as an error compensation model to compensate the error of the un-modeled part of the mechanism model, and gives a reasonable estimate of the uncertain part of the model, which theoretically reduce the prediction error of the model. The Matlab simulation results show that the prediction error of the hybrid model is significantly lower than that of the mechanism model and the data model, and can be adapted to the measurement needs of the industrial site.},
author = {Xiao, Dong and Xie, Hongfei and Jiang, Longqiang and Le, Ba Tuan and Wang, Jichun and Liu, Chong Min and Li, Hongzong},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Research on a method for predicting the underflow concentration of a thickener based on the hybrid model.pdf:pdf},
issn = {1997003X},
journal = {Engineering Applications of Computational Fluid Mechanics},
keywords = {EDO,Hydrometallurgy,TELM,hybrid model,mechanism model,underflow concentration},
mendeley-groups = {thickener},
number = {1},
pages = {13--26},
title = {{Research on a method for predicting the underflow concentration of a thickener based on the hybrid model}},
volume = {14},
year = {2020}
}
@article{Tan2015,
abstract = {Paste thickeners have attracted significant interest from mining industry due to its higher dewatering ability as compared to conventional or high rate thickeners. However, the underflow solids concentration, which is an important process variable of thickeners, is often poorly regulated. In this article, a dynamic model based on sedimentation-consolidation theory is adopted and validated using industrial plant data. Based on this model, control studies have been carried out to explore approaches to address a number of difficulties in current industrial operation. An extended Kalman filter is developed to estimate the compressibility parameter of the feed (coal tailing). As a key process parameter, coal tailing compressibility plays a significant role in thickener dynamics, but is time-varying and difficult to measure. Potential improvements of process operation by implementing model predictive control (MPC) are investigated. Simulation studies show that the proposed control can deliver a higher underflow solids concentration and a better regulated underflow removal rate than the existing operation. It is also demonstrated that taking into account the "future" time-varying input constraints in the MPC algorithm can help overcome the current control difficulty caused by co-disposal of coal tailing and coarse reject.},
author = {Tan, Chee Keong and Setiawan, Ridwan and Bao, Jie and Bickert, G{\"{o}}tz},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S0959152415000293-main.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Kalman filter Time-varying constraints,Mineral processing,Model predictive control,Sedimentation-consolidation model},
mendeley-groups = {thickener},
pages = {1--8},
publisher = {Elsevier Ltd},
title = {{Studies on parameter estimation and model predictive control of paste thickeners}},
volume = {28},
year = {2015}
}
@article{Zhang2018,
abstract = {Industrial Internet of Things (IIoT) is producing massive data which are valuable for knowing running status of the underlying equipment. However, these data involve various operation events that span some time, which raise questions on how to model long memory of states, and how to predict the running status based on historical data accurately. This paper aims to develop a method of: (1) analyzing equipment working condition based on the sensed data; (2) building a prediction model for working status forecasting and designing a deep neural network model to predict equipment running data; and (3) improving the prediction accuracy by systematic feature engineering and optimal hyperparameter searching. We evaluate our method with real-world monitoring data collected from 33 sensors of a main pump in a power station for three months. The model achieves less root mean square error than that of autoregressive integrated moving average model. Our method is applicable to general IIoT equipment for analyzing time series data and forecasting operation status.},
author = {Zhang, Weishan and Guo, Wuwu and Liu, Xin and Liu, Yan and Zhou, Jiehan and Li, Bo and Lu, Qinghua and Yang, Su},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/08335287.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {LSTM model,Time series prediction,industry Internet of Things,power equipment},
mendeley-groups = {time series},
pages = {23551--23560},
title = {{LSTM-Based Analysis of Industrial IoT Equipment}},
volume = {6},
year = {2018}
}
@article{Elman1990,
author = {Elman, Jeffrey L.},
title = {Finding Structure in Time},
journal = {Cognitive Science},
volume = {14},
number = {2},
pages = {179-211},
year = {1990}
}
@article{Yuan2020,
abstract = {This paper focuses on the time series prediction problem for underflow concentration of deep cone thickener. It is commonly used in the industrial sedimentation process. In this paper, we introduce a dual attention neural network method to model both spatial and temporal features of the data collected from multiple sensors in the thickener to predict underflow concentration. The concentration is the key factor for future mining process. This model includes encoder and decoder. Their function is to capture spatial and temporal importance separately from input data, and output more accurate prediction. We also consider the domain knowledge in modeling process. Several supplementary constructed features are examined to enhance the final prediction accuracy in addition to the raw data from sensors. To test the feasibility and efficiency of this method, we select an industrial case based on Industrial Internet of Things (IIoT). This Tailings Thickener is from FLSmidth with multiple sensors. The comparative results support this method has favorable prediction accuracy, which is more than 10{\%} lower than other time series prediction models in some common error indices. We also try to interpret our method with additional ablation experiments for different features and attention mechanisms. By employing mean absolute error index to evaluate the models, experimental result reports that enhanced features and dual-attention modules reduce error of fitting {\~{}}5{\%} and {\~{}}11{\%}, respectively.},
author = {Yuan, Zhaolin and Hu, Jinlong and Wu, Di and Ban, Xiaojuan},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/A Dual-Attention Recurrent Neural Network Method for Deep Cone Thickener Underflow Concentration Prediction.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Cone thickener,Dual-attention,Industrial internet of things (IIoT),Spatio-temporal relationship,Time series prediction},
mendeley-groups = {myself},
number = {5},
pages = {1--18},
pmid = {32110906},
title = {{A dual-attention recurrent neural network method for deep cone thickener underflow concentration prediction}},
volume = {20},
year = {2020}
}
@online{2020arXiv200207526Y,
  author    = {Shuoheng Yang and
               Yuxin Wang and
               Xiaowen Chu},
  title     = {A Survey of Deep Learning Techniques for Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2002.07526},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.07526},
  eprinttype = {arXiv},
  eprint    = {2002.07526},
  timestamp = {Mon, 02 Mar 2020 16:46:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-07526.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Geffner2018,
author = {Geffner, Hector},
title = {Model-Free, Model-Based, and General Intelligence},
year = {2018},
isbn = {9780999241127},
publisher = {AAAI Press},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {10–17},
numpages = {8},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@incollection{GUIDOLIN2018113,
title = "Chapter 4 - Unit Roots and Cointegration",
editor = "Massimo Guidolin and Manuela Pedio",
booktitle = "Essentials of Time Series for Financial Applications",
publisher = "Academic Press",
pages = "113 - 149",
year = "2018",
isbn = "978-0-12-813409-2",
author = "Massimo Guidolin and Manuela Pedio",
keywords = "Nonstationarity, unit root, deterministic trend, cointegration, vector error-correction model, common stochastic trends",
abstract = "This chapter investigates the consequences of nonstationarity (in the form of unit roots in the assumed ARMA representation of a time series) for the econometric methodologies that have been developed in Chapters 1–3. Section 4.1 defines unit root processes and explains what it means to detrend such processes. Section 4.2 gives information about problems caused by the use of nonstationary, trending series in regression analysis. Section 4.3 describes the tests that can be used to verify the presence of a unit root in a series, in particular the Dickey–Fuller and the augmented Dickey–Fuller tests, along with those proposed by Philips and Perron and by Kwiatkowski, Phillips, Schmidt, and Shin. Finally, Section 4.4 introduces the concept of cointegration; it explains how to test for the presence of cointegrated variables, and the fact that the presence of cointegration always implies a vector error-correction model representation."
}% 

@article{kelly2020,
  title={Learning differential equations that are easy to solve},
  author={Kelly, Jacob and Bettencourt, Jesse and Johnson, Matthew J and Duvenaud, David K},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4370--4380},
  year={2020}
}
@article{poli2020,
  title={Hypersolvers: Toward fast continuous-depth models},
  author={Poli, Michael and Massaroli, Stefano and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21105--21117},
  year={2020}
}

@inproceedings{J2020,
  title={How to train your neural ODE},
  author={Finlay, Chris and Jacobsen, J{\"o}rn-Henrik and Nurbekyan, Levon and Oberman, Adam},
  booktitle={International Conference on Machine Learning},
  pages={3154--3164},
  year={2020},
  organization={PMLR}
}
@article{zhao2019online,
  title={Online reinforcement learning control algorithm for concentration of thickener underflow},
  author={Yuan, Zhao-Lin and He, Run-Zi and Yao, Chao and Li, Jia and Ban, Xiao-Juan and Li, Xiao-Rui},
  journal={Acta Automatica Sinica},
  volume={45},
  pages={1--15},
  year={2019}
}
@article{jay2020recent,
  title={Recent advances and prospects in industrial AI and applications},
  author={Jay, Lee and Li Xiang and Xu Yuan-Ming and Yang Shaojie and Sun Ke-Yi},
  journal={Acta Automatica Sinica},
  volume={46},
  number={10},
  pages={2031--2044},
  year={2020}
}
@article{tian2020development,
  title={Development directions of industrial artificial intelligence},
  author={Chai, Tian-You},
  journal={Acta Automatica Sinica},
  volume={46},
  number={10},
  pages={2005--2012},
  year={2020}
}
@article{mercere2011parameterization,
  title={Parameterization and identification of multivariable state-space systems: A canonical approach},
  author={Merc{\`e}re, Guillaume and Bako, Laurent},
  journal={Automatica},
  volume={47},
  number={8},
  pages={1547--1555},
  year={2011},
  publisher={Elsevier}
}
@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}
@article{Rangapuram2018,
abstract = {We present a novel approach to probabilistic time series forecasting that combines state space models with deep learning. By parametrizing a per-time-series linear state space model with a jointly-learned recurrent neural network, our method retains desired properties of state space models such as data efficiency and inter-pretability, while making use of the ability to learn complex patterns from raw data offered by deep learning approaches. Our method scales gracefully from regimes where little training data is available to regimes where data from large collection of time series can be leveraged to learn accurate models. We provide qualitative as well as quantitative results with the proposed method, showing that it compares favorably to the state-of-the-art.},
author = {Rangapuram, Syama Sundar and Seeger, Matthias and Gasthaus, Jan and Stella, Lorenzo and Wang, Yuyang and Januschowski, Tim},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/8004-deep-state-space-models-for-time-series-forecasting.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {system{\_}identify,SEQ{\_}VAE},
number = {NeurIPS},
pages = {7785--7794},
title = {{Deep state space models for time series forecasting}},
volume = {2018-Decem},
year = {2018}
}
@article{ma2020data,
  title={Data augmentation in microscopic images for material data mining},
  author={Ma, Boyuan and Wei, Xiaoyan and Liu, Chuni and Ban, Xiaojuan and Huang, Haiyou and Wang, Hao and Xue, Weihua and Wu, Stephen and Gao, Mingfei and Shen, Qing and others},
  journal={npj Computational Materials},
  volume={6},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{young2018recent,
  title={Recent trends in deep learning based natural language processing},
  author={Young, Tom and Hazarika, Devamanyu and Poria, Soujanya and Cambria, Erik},
  journal={ieee Computational intelligenCe magazine},
  volume={13},
  number={3},
  pages={55--75},
  year={2018},
  publisher={IEEE}
}
@article{voulodimos2018deep,
  title={Deep learning for computer vision: A brief review},
  author={Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  journal={Computational intelligence and neuroscience},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}
@article{ma2021sesf,
  title={Sesf-fuse: An unsupervised deep model for multi-focus image fusion},
  author={Ma, Boyuan and Zhu, Yu and Yin, Xiang and Ban, Xiaojuan and Huang, Haiyou and Mukeshimana, Michele},
  journal={Neural Computing and Applications},
  volume={33},
  number={11},
  pages={5793--5804},
  year={2021},
  publisher={Springer}
}
@article{DIAZ2021106760,
title = {Random forest model predictive control for paste thickening},
journal = {Minerals Engineering},
volume = {163},
pages = {106760},
year = {2021},
issn = {0892-6875},
author = {Pablo Diaz and Juan C. Salas and Aldo Cipriano and Felipe Núñez},
keywords = {Paste thickening, Model predictive control, Random forest, Machine learning},
abstract = {As processes involved in mineral processing operations increase their complexity, automation and control become critical to ensure an economically viable and environmentally sustainable operation. In the context of modern mineral processing, paste thickening stands out as a relatively new method for producing high density slurries that has proven challenging for standard control algorithms. In this setting, the use of machine-learning-based models within a predictive control strategy arises as an appealing alternative. This work presents a Random Forest Model Predictive Control scheme for paste thickening based on a purely data-driven approach for modeling and evolutionary strategies for solving the associated optimization problem. Results show that the proposed strategy outperforms conventional predictive control both qualitatively and quantitatively.}
}
@INPROCEEDINGS{9429523,
  author={Oulhiq, Ridouane and Benjelloun, Khalid and Kali, Yassine and Saad, Maarouf},
  booktitle={2021 18th International Multi-Conference on Systems, Signals   Devices (SSD)}, 
  title={Identification and Control of an Industrial Thickener Using Historical Data}, 
  year={2021},
  volume={},
  number={},
  pages={915-920}
  }
  
  
@phdthesis{hazlin2020solving,
  title={Solving first order ordinary differential equation using adaptive Runge-Kutta method},
  author={Hazlin, Syauqina Nadia},
  year={2020},
  school={Universiti Teknologi MARA}
}

@article{Wu2020,
author = {Wu, Sifan and Xiao, Xi and Ding, Qianggang and Zhao, Peilin and Wei, Ying and Huang, Junzhou},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {17105--17115},
title = {{Adversarial Sparse Transformer for Time Series Forecasting}},
volume = {33},
year = {2020}
}
@article{liu2017survey,
  title={A survey of deep neural network architectures and their applications},
  author={Liu, Weibo and Wang, Zidong and Liu, Xiaohui and Zeng, Nianyin and Liu, Yurong and Alsaadi, Fuad E},
  journal={Neurocomputing},
  volume={234},
  pages={11--26},
  year={2017},
  publisher={Elsevier}
}
@article{luo2017inherently,
  title={An inherently nonnegative latent factor model for high-dimensional and sparse matrices from industrial applications},
  author={Luo, Xin and Zhou, MengChu and Li, Shuai and Shang, MingSheng},
  journal={IEEE Transactions on Industrial Informatics},
  volume={14},
  number={5},
  pages={2011--2022},
  year={2017},
  publisher={IEEE}
}
@article{luo2017incorporation,
  title={Incorporation of efficient second-order solvers into latent factor models for accurate prediction of missing QoS data},
  author={Luo, Xin and Zhou, MengChu and Li, Shuai and Xia, Yunni and You, Zhu-Hong and Zhu, QingSheng and Leung, Hareton},
  journal={IEEE transactions on cybernetics},
  volume={48},
  number={4},
  pages={1216--1228},
  year={2017},
  publisher={IEEE}
}
@article{wu2020data,
  title={A data-characteristic-aware latent factor model for web services QoS prediction},
  author={Wu, Di and Luo, Xin and Shang, Mingsheng and He, Yi and Wang, Guoyin and Wu, Xindong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2020},
  publisher={IEEE}
}
@ARTICLE{8681080,
  author={Lu, Huiyan and Jin, Long and Luo, Xin and Liao, Bolin and Guo, Dongsheng and Xiao, Lin},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={RNN for Solving Perturbed Time-Varying Underdetermined Linear System With Double Bound Limits on Residual Errors and State Variables}, 
  year={2019},
  volume={15},
  number={11},
  pages={5931-5942}
  }
  
@ARTICLE{8945486,
  author={Kebria, Parham M. and Khosravi, Abbas and Salaken, Syed Moshfeq and Nahavandi, Saeid},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Deep imitation learning for autonomous vehicles based on convolutional neural networks}, 
  year={2020},
  volume={7},
  number={1},
  pages={82-95},
  }
 @ARTICLE{9522017,
  author={Fei, Juntao and Liu, Lunhaojie},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Real-Time Nonlinear Model Predictive Control of Active Power Filter Using Self-Feedback Recurrent Fuzzy Neural Network Estimator}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  }
  
  @article{neu2021systematic,
  title={A systematic literature review on state-of-the-art deep learning methods for process prediction},
  author={Neu, Dominic A and Lahann, Johannes and Fettke, Peter},
  journal={Artificial Intelligence Review},
  pages={1--27},
  year={2021},
  publisher={Springer}
}
@article{larsson2002identification,
  title={Identification of continuous-time AR processes from unevenly sampled data},
  author={Larsson, Erik K and S{\"o}derstr{\"o}m, Torsten},
  journal={Automatica},
  volume={38},
  number={4},
  pages={709--718},
  year={2002},
  publisher={Elsevier}
}
@article{yin2020systematic,
  title={A systematic review of paste technology in metal mines for cleaner production in China},
  author={Yin, Shenghua and Shao, Yajian and Wu, Aixiang and Wang, Hongjiang and Liu, Xiaohui and Wang, Yong},
  journal={Journal of Cleaner Production},
  volume={247},
  pages={119590},
  year={2020},
  publisher={Elsevier}
}
@article{wu2020optimization,
  title={Optimization of flocculation and settling parameters of tailings slurry by response surface methodology},
  author={Wu, Aixiang and Ruan, Zhuen and B{\"u}rger, Raimund and Yin, Shenghua and Wang, Jiandong and Wang, Yong},
  journal={Minerals Engineering},
  volume={156},
  pages={106488},
  year={2020},
  publisher={Elsevier}
}
@article{li2019evaluation,
  title={Evaluation of short-term strength development of cemented backfill with varying sulphide contents and the use of additives},
  author={Li, Hong and Wu, Aixiang and Wang, Hongjiang},
  journal={Journal of environmental management},
  volume={239},
  pages={279--286},
  year={2019},
  publisher={Elsevier}
}
@article{christoffersen2001forecasting,
  title={Forecasting Non-Stationary Economic Time Series},
  author={Christoffersen, Peter F},
  journal={Journal of the American Statistical Association},
  volume={96},
  number={453},
  pages={347--347},
  year={2001},
  publisher={American Statistical Association}
}
@article{bogacki19893,
  title={A 3 (2) pair of Runge-Kutta formulas},
  author={Bogacki, Przemyslaw and Shampine, Lawrence F},
  journal={Applied Mathematics Letters},
  volume={2},
  number={4},
  pages={321--325},
  year={1989},
  publisher={Elsevier}
}
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}
@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{duan2016,
  title={深度学习在控制领域的研究现状与展望},
  author={段艳杰 and 吕宜生 and 张杰 and 赵学亮 and 王飞跃},
  journal={自动化学报},
  volume={42},
  number={5},
  pages={643--654},
  year={2016}
}
@book{shumway2000time,
  title={Time series analysis and its applications},
  author={Shumway, Robert H and Stoffer, David S and Stoffer, David S},
  volume={3},
  year={2000},
  publisher={Springer}
}
@article{delgado1995dynamic,
  title={Dynamic recurrent neural network for system identification and control},
  author={Delgado, A and Kambhampati, C and Warwick, Kevin},
  journal={IEE Proceedings-Control Theory and Applications},
  volume={142},
  number={4},
  pages={307--314},
  year={1995},
  publisher={IET}
}
@article{zamarreno1998state,
  title={State space neural network. Properties and application},
  author={Zamarre{\~n}o, Jes{\'u}s M and Vega, Pastora},
  journal={Neural networks},
  volume={11},
  number={6},
  pages={1099--1112},
  year={1998},
  publisher={Elsevier}
}
@article{tan1996nonlinear,
  title={Nonlinear one-step-ahead control using neural networks: control strategy and stability design},
  author={Tan, Yonghong and Van Cauwenberghe, Achiel},
  journal={Automatica},
  volume={32},
  number={12},
  pages={1701--1706},
  year={1996},
  publisher={Elsevier}
}
@article{temeng1995model,
  title={Model predictive control of an industrial packed bed reactor using neural networks},
  author={Temeng, Kwaku O and Schnelle, Phillip D and McAvoy, Thomas J},
  journal={Journal of Process Control},
  volume={5},
  number={1},
  pages={19--27},
  year={1995},
  publisher={Elsevier}
}
@article{le2013system,
  title={System identification: new paradigms, challenges, and opportunities},
  author={Le-Yi, Wang and Wen-Xiao, Zhao},
  journal={Acta automatica sinica},
  volume={39},
  number={7},
  pages={933--942},
  year={2013},
  publisher={Elsevier}
}
@article{gevers2006personal,
  title={A personal view of the development of system identification: A 30-year journey through an exciting field},
  author={Gevers, Michel},
  journal={IEEE Control systems magazine},
  volume={26},
  number={6},
  pages={93--105},
  year={2006},
  publisher={IEEE}
}
@article{ljung2008perspectives,
  title={Perspectives on system identification},
  author={Ljung, Lennart},
  journal={IFAC Proceedings Volumes},
  volume={41},
  number={2},
  pages={7172--7184},
  year={2008},
  publisher={Elsevier}
}
@article{ljung2011four,
  title={Four encounters with system identification},
  author={Ljung, Lennart and Hjalmarsson, H{\aa}kan and Ohlsson, Henrik},
  journal={European Journal of Control},
  volume={17},
  number={5-6},
  pages={449--471},
  year={2011},
  publisher={Elsevier}
}
@article{funahashi1993approximation,
  title={Approximation of dynamical systems by continuous time recurrent neural networks},
  author={Funahashi, Ken-ichi and Nakamura, Yuichi},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={801--806},
  year={1993},
  publisher={Elsevier}
}
@inproceedings{demeester2020system,
  title={System identification with time-aware neural sequence models},
  author={Demeester, Thomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3757--3764},
  year={2020}
}
@inproceedings{Zhuang2020,
  title={Adaptive checkpoint adjoint method for gradient estimation in neural ode},
  author={Zhuang, Juntang and Dvornek, Nicha and Li, Xiaoxiao and Tatikonda, Sekhar and Papademetris, Xenophon and Duncan, James},
  booktitle={International Conference on Machine Learning},
  pages={11639--11649},
  year={2020},
  organization={PMLR}
}
@inproceedings{Oganesyan2020,
  title={Stochasticity in neural odes: an empirical study},
  author={Volokhova, Alexandra and Oganesyan, Viktor and Vetrov, Dmitry},
  booktitle={ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations},
  year={2020}
}
@article{Ghosh2020,
  title={Steer: Simple temporal regularization for neural ode},
  author={Ghosh, Arnab and Behl, Harkirat and Dupont, Emilien and Torr, Philip and Namboodiri, Vinay},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14831--14843},
  year={2020}
}

@InProceedings{OISR,
  author    = {Xiangyu He and Zitao Mo and Peisong Wang and Yang Liu and Mingyuan Yang and Jian Cheng},
  title     = {ODE-inspired Network Design for Single Image Super-Resolution},
  booktitle = {2019 {IEEE} Conference on Computer Vision and Pattern Recognition},
  month     = {July},
  year      = {2019}
}
@article{Huang2020,
  title={Learning continuous system dynamics from irregularly-sampled partial observations},
  author={Huang, Zijie and Sun, Yizhou and Wang, Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16177--16187},
  year={2020}
}

@inproceedings{morrill2021neural,
  title={Neural rough differential equations for long time series},
  author={Morrill, James and Salvi, Cristopher and Kidger, Patrick and Foster, James},
  booktitle={International Conference on Machine Learning},
  pages={7829--7838},
  year={2021},
  organization={PMLR}
}
@inproceedings{Yildiz2021,
author = {Yildiz, Cagatay and Heinonen, Markus and L{\"{a}}hdesm{\"{a}}ki, Harri},
booktitle = {International Conference on Machine Learning},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Heinonen - 2020 - Continuous-Time Model-Based Reinforcement Learning.pdf:pdf},
isbn = {2640-3498},
mendeley-groups = {RL_control},
pages = {12009--12018},
publisher = {PMLR},
title = {{Continuous-time Model-based Reinforcement Learning}},
year = {2021}
}
@inproceedings{li2020scalable,
  title={Scalable gradients for stochastic differential equations},
  author={Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky TQ and Duvenaud, David},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3870--3882},
  year={2020},
  organization={PMLR}
}
@online{morrill2021online,
  title={Neural Controlled Differential Equations for Online Prediction Tasks},
  author={Morrill, James and Kidger, Patrick and Yang, Lingyi and Lyons, Terry},
  journal={arXiv preprint arXiv:2106.11028},
  url={https://arxiv.org/abs/2106.11028},
  doi={,},
  year={2021}
}
@online{ayed2019learning,
  title={Learning dynamical systems from partial observations},
  author={Ayed, Ibrahim and de B{\'e}zenac, Emmanuel and Pajot, Arthur and Brajard, Julien and Gallinari, Patrick},
  publisher={arXiv preprint arXiv:1902.11136},
  address={https://arxiv.org/abs/1902.11136},
  doi={,},
  year={2019}
}
@online{lechner2020learning,
  title={Learning long-term dependencies in irregularly-sampled time series},
  author={Lechner, Mathias and Hasani, Ramin},
  journal={arXiv preprint arXiv:2006.04418},
  url={https://arxiv.org/abs/2006.04418},
  year={2020},
  doi={,},
}
@inproceedings{Grathwohl2019,
  author    = {Will Grathwohl and
               Ricky T. Q. Chen and
               Jesse Bettencourt and
               Ilya Sutskever and
               David Duvenaud},
  title     = {{FFJORD:} Free-Form Continuous Dynamics for Scalable Reversible Generative
               Models},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=rJxgknCcK7},
  timestamp = {Thu, 25 Jul 2019 13:03:15 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/GrathwohlCBSD19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Jia2019,
  title={Neural Jump Stochastic Differential Equations},
  author={J. Jia and Austin R. Benson},
  booktitle={Neural Information Processing Systems},
  year={2019}
}
@inproceedings{Ainsworth2020,
  title={Faster Policy Learning with Continuous-Time Gradients},
  author={Ainsworth, Samuel and Lowrey, Kendall and Thickstun, John and Harchaoui, Zaid and Srinivasa, Siddhartha},
  booktitle={Learning for Dynamics and Control},
  pages={1054--1067},
  year={2021},
  organization={PMLR}
}

@inproceedings{jia2019focnet,
  title={Focnet: A fractional optimal control network for image denoising},
  author={Jia, Xixi and Liu, Sanyang and Feng, Xiangchu and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6054--6063},
  year={2019}
}
@inproceedings{chen2021continuous,
  title={Continuous-time attention for sequential learning},
  author={Chen, Yi-Hsiang and Chien, Jen-Tzung},
  booktitle={Proc. of AAAI Conference on Aritificial Intelligence},
  year={2021}
}
@inproceedings{Liu2020,
  title={Learning to encode position for transformer with continuous dynamical model},
  author={Liu, Xuanqing and Yu, Hsiang-Fu and Dhillon, Inderjit and Hsieh, Cho-Jui},
  booktitle={International conference on machine learning},
  pages={6327--6335},
  year={2020},
  organization={PMLR}
}
@article{Vaswani2017,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{Zhou2020,
  title={Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={12},
  pages={11106--11115},
  year={2021}
}
@article{Wu2021,
  title={Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22419--22430},
  year={2021}
}
@article{Ljung2020,
  title={Deep learning and system identification},
  author={Ljung, Lennart and Andersson, Carl and Tiels, Koen and Sch{\"o}n, Thomas B},
  journal={IFAC-PapersOnLine},
  volume={53},
  number={2},
  pages={1175--1181},
  year={2020},
  publisher={Elsevier}
}


@article{Yin2014,
  title={Real-time implementation of fault-tolerant control systems with performance optimization},
  author={Yin, Shen and Luo, Hao and Ding, Steven X},
  journal={IEEE Transactions on Industrial Electronics},
  volume={61},
  number={5},
  pages={2402--2411},
  year={2013},
  publisher={IEEE}
}



@article{Kouro2009,
  title={Model predictive control—A simple and powerful method to control power converters},
  author={Kouro, Samir and Cort{\'e}s, Patricio and Vargas, Ren{\'e} and Ammann, Ulrich and Rodr{\'\i}guez, Jos{\'e}},
  journal={IEEE Transactions on industrial electronics},
  volume={56},
  number={6},
  pages={1826--1838},
  year={2008},
  publisher={IEEE}
}


@article{Dai2015,
  title={Data-driven optimization control for safety operation of hematite grinding process},
  author={Dai, Wei and Chai, Tianyou and Yang, Simon X},
  journal={IEEE Transactions on Industrial Electronics},
  volume={62},
  number={5},
  pages={2930--2941},
  year={2014},
  publisher={IEEE}
}

@article{Wang2016,
  title={Data-based adaptive critic designs for nonlinear robust optimal control with uncertain dynamics},
  author={Wang, Ding and Liu, Derong and Zhang, Qichao and Zhao, Dongbin},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  volume={46},
  number={11},
  pages={1544--1555},
  year={2015},
  publisher={IEEE}
}


@book{Sutton2018,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@book{F.L.LewisD.Vrabie2012,
  title={Optimal control},
  author={Lewis, Frank L and Vrabie, Draguna and Syrmos, Vassilis L},
  year={2012},
  publisher={John Wiley \& Sons}
}



@article{Prokhorov1997,
  title={Adaptive critic designs},
  author={Prokhorov, Danil V and Wunsch, Donald C},
  journal={IEEE transactions on Neural Networks},
  volume={8},
  number={5},
  pages={997--1007},
  year={1997},
  publisher={IEEE}
}

@article{Werbos2008,
  title={Foreword: ADP-The Key Direction for Future Research in Intelligent Control and Understanding Brain Intelligence.},
  author={Werbos, Paul J},
  journal={IEEE Trans. Syst. Man Cybern. Part B},
  volume={38},
  number={4},
  pages={898--900},
  year={2008}
}



@article{Duan:643,
  title={Deep learning for control: the state of the art and prospects},
  author={Duan, YJ and Lv, YS and Zhang, Jie and Zhao, XL and Wang, FY},
  journal={Acta Automatica Sinica},
  volume={42},
  number={5},
  pages={643--654},
  year={2016}
}


@article{Liu2015,
  title={Reinforcement learning design-based adaptive tracking control with less learning parameters for nonlinear discrete-time MIMO systems},
  author={Liu, Yan-Jun and Tang, Li and Tong, Shaocheng and Chen, CL Philip and Li, Dong-Juan},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={26},
  number={1},
  pages={165--176},
  year={2014},
  publisher={IEEE}
}



@article{LiuL2017,
  title={Adaptive fault-tolerant tracking control for MIMO discrete-time systems via reinforcement learning algorithm with less learning parameters},
  author={Liu, Lei and Wang, Zhanshan and Zhang, Huaguang},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={14},
  number={1},
  pages={299--313},
  year={2016},
  publisher={IEEE}
}



@article{XuX2017,
  title={Self-learning control using dual heuristic programming with global Laplacian eigenmaps},
  author={Xu, Xin and Yang, Huiyuan and Lian, Chuanqiang and Liu, Jiahang},
  journal={IEEE Transactions on Industrial Electronics},
  volume={64},
  number={12},
  pages={9517--9526},
  year={2017},
  publisher={IEEE}
}


@article{Wei2014,
  title={Adaptive dynamic programming for optimal tracking control of unknown nonlinear systems with application to coal gasification},
  author={Wei, Qinglai and Liu, Derong},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={11},
  number={4},
  pages={1020--1036},
  year={2013},
  publisher={IEEE}
}


@article{Jiang2018,
  title={Data-driven flotation industrial process operational optimal control based on reinforcement learning},
  author={Jiang, Yi and Fan, Jialu and Chai, Tianyou and Li, Jinna and Lewis, Frank L},
  journal={IEEE Transactions on Industrial Informatics},
  volume={14},
  number={5},
  pages={1974--1989},
  year={2017},
  publisher={IEEE}
}


@article{Jiang2019,
  title={Dual-rate operational optimal control for flotation industrial process with unknown operational model},
  author={Jiang, Yi and Fan, Jialu and Chai, Tianyou and Lewis, Frank L},
  journal={IEEE Transactions on Industrial Electronics},
  volume={66},
  number={6},
  pages={4587--4599},
  year={2018},
  publisher={IEEE}
}



@article{Modares2014,
  title={Integral reinforcement learning and experience replay for adaptive optimal control of partially-unknown constrained-input continuous-time systems},
  author={Modares, Hamidreza and Lewis, Frank L and Naghibi-Sistani, Mohammad-Bagher},
  journal={Automatica},
  volume={50},
  number={1},
  pages={193--202},
  year={2014},
  publisher={Elsevier}
}

@article{Mnih2013,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  eprinttype = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{Wang2012-GDHP,
  title={Optimal control of unknown nonaffine nonlinear discrete-time systems based on adaptive dynamic programming},
  author={Wang, Ding and Liu, Derong and Wei, Qinglai and Zhao, Dongbin and Jin, Ning},
  journal={Automatica},
  volume={48},
  number={8},
  pages={1825--1832},
  year={2012},
  publisher={Elsevier}
}



@article{Chai2016,
  title={An intelligent switching control for a mixed separation thickener process},
  author={Chai, Tianyou and Jia, Yao and Li, Haibo and Wang, Hong},
  journal={Control Engineering Practice},
  volume={57},
  pages={61--71},
  year={2016},
  publisher={Elsevier}
}



@article{WangLinyan2017,
  title={Dual-rate adaptive control for mixed separation thickening process using compensation signal based approach},
  author={Wang, Linyan and Jia, Yao and Chai, Tianyou and Xie, Wenfang},
  journal={IEEE Transactions on Industrial Electronics},
  volume={65},
  number={4},
  pages={3621--3632},
  year={2017},
  publisher={IEEE}
}

@phdthesis{WangMeng,
  title={矿浆中和沉降分离过程模型软件的研发},
  author={王猛},
  school={东北大学},
    year={2011},
}


@book{Tang2009,
  title={湿法冶金设备},
  author={唐谟堂},
  publisher={湿法冶金设备},
  year={2009},
}


@article{Wang330,
  title={混合选别浓密过程双速率智能切换控制},
  author={王琳岩 and 李健 and 贾瑶 and 柴天佑},
  journal={自动化学报},
  volume={44},
  number={2},
  pages={330--343},
  year={2018}
}



@article{Luo2016,
  title={Model-free optimal tracking control via critic-only Q-learning},
  author={Luo, Biao and Liu, Derong and Huang, Tingwen and Wang, Ding},
  journal={IEEE transactions on neural networks and learning systems},
  volume={27},
  number={10},
  pages={2134--2144},
  year={2016},
  publisher={IEEE}
}

@article{Padhi2006,
  title={A single network adaptive critic (SNAC) architecture for optimal control synthesis for a class of nonlinear systems},
  author={Padhi, Radhakant and Unnikrishnan, Nishant and Wang, Xiaohua and Balakrishnan, SN},
  journal={Neural Networks},
  volume={19},
  number={10},
  pages={1648--1660},
  year={2006},
  publisher={Elsevier}
}


@article{Xu2015,
  title={An intelligent control strategy for thickening process},
  author={Xu, Ning and Wang, Xu and Zhou, Junwu and Wang, Qingkai and Fang, Wen and Peng, Xiuyun},
  journal={International Journal of Mineral Processing},
  volume={142},
  pages={56--62},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{Ojeda2014,
  title={Intelligent control of an industrial thickener},
  author={Ojeda, Pablo and Bergh, Luis G and Torres, Luis},
  booktitle={2014 13th International Conference on Control Automation Robotics \& Vision (ICARCV)},
  pages={505--510},
  year={2014},
  organization={IEEE}
}


@article{Li2018,
  title={Off-policy Q-learning: Set-point design for optimizing dual-rate rougher flotation operational processes},
  author={Li, Jinna and Chai, Tianyou and Lewis, Frank L and Fan, Jialu and Ding, Zhengtao and Ding, Jinliang},
  journal={IEEE Transactions on Industrial Electronics},
  volume={65},
  number={5},
  pages={4092--4102},
  year={2017},
  publisher={IEEE}
}

@article{Xue2019,
  title={New methods for optimal operational control of industrial processes using reinforcement learning on two time scales},
  author={Xue, Wenqian and Fan, Jialu and Lopez, Victor G and Li, Jinna and Jiang, Yi and Chai, Tianyou and Lewis, Frank L},
  journal={IEEE Transactions on Industrial Informatics},
  volume={16},
  number={5},
  pages={3085--3099},
  year={2019},
  publisher={IEEE}
}
@article{Oulhiq2021,
author = {Oulhiq, Ridouane and Benjelloun, Khalid and Kali, Yassine and Saad, Maarouf},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Identification_and_Control_of_an_Industrial_Thickener_Using_Historical_Data.pdf:pdf},
isbn = {9781665414937},
journal = {18th IEEE International Multi-Conference on Systems, Signals and Devices, SSD 2021},
keywords = {Dynamic modeling,Historical data,Model predictive control,Thickener},
pages = {915--920},
title = {{Identification and Control of an Industrial Thickener Using Historical Data}},
year = {2021}
}
@article{Member2019,
author = {N{\'{u}}{\~{n}}ez, Felipe and Langarica, Sa{\'{u}}l and D{\'{i}}az, Pablo and Torres, Mario and Salas, Juan Carlos},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/N{\'{u}}{\~{n}}ez et al. - 2020 - Neural Network-Based Model Predictive Control of a Paste Thickener over an Industrial Internet Platform.pdf:pdf},
issn = {19410050},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Industrial Internet of Things (IIoT),Industrial automation,mineral processing,predictive control},
number = {4},
pages = {2859--2867},
title = {{Neural Network-Based Model Predictive Control of a Paste Thickener over an Industrial Internet Platform}},
volume = {16},
year = {2020}
}
@article{Langlois2019,
author = {Langlois, Juan I. and Cipriano, Aldo},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Dynamic modeling and simulation of tailing thickener units for the development of control strategies_.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Dynamic simulation,Flocculation,Numerical simulation,Particle size distribution,Sedimentation-consolidation model,Yield stress},
number = {May 2018},
pages = {131--139},
title = {{Dynamic modeling and simulation of tailing thickener units for the development of control strategies.}},
volume = {131},
year = {2019}
}
@article{Shin2020,
abstract = {Over the past few decades, advanced process control (APC) such as model predictive control (MPC) has been introduced to process industry to enhance its operational efficiency. For this, a linear model has been widely used to reduce the computational burden for iterative simulation and optimization over time, but it caused high inaccuracy of the control system. In this study, an artificial neural network (ANN) model was adopted instead of using the existing linearized model in order to increase the speed of optimization and accuracy of the model. For a case study, a depropanizer was modeled using Aspen HYSYS, and all feasible operation scenarios were considered to generate massive amounts of dynamic simulation data. Then, the accumulated data was implemented to the ANN for training, and it was tested. Once the verification was completed, the model was incorporated with an optimization algorithm in MPC system. For testing its performance, set point change and introduction of disturbances were applied to the model, and efficiency of the MPC was compared with the conventional control such as PID feedback control. The analysis results showed better performance (i.e., shorter settling time and rise time) of the MPC against the PID control. This methodology can be widely used in various types of control systems in the industry.},
author = {Shin, Yeonju and Smith, Robin and Hwang, Sungwon},
doi = {10.1016/j.jclepro.2020.124124},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S095965262034169X-main.pdf:pdf},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Artificial neural networks,Model predictive control,Modeling,Optimization},
pages = {124124},
publisher = {Elsevier Ltd},
title = {{Development of model predictive control system using an artificial neural network: A case study with a distillation column}},
url = {https://doi.org/10.1016/j.jclepro.2020.124124},
volume = {277},
year = {2020}
}
@article{Diaz2021,
abstract = {As processes involved in mineral processing operations increase their complexity, automation and control become critical to ensure an economically viable and environmentally sustainable operation. In the context of modern mineral processing, paste thickening stands out as a relatively new method for producing high density slurries that has proven challenging for standard control algorithms. In this setting, the use of machine-learning-based models within a predictive control strategy arises as an appealing alternative. This work presents a Random Forest Model Predictive Control scheme for paste thickening based on a purely data-driven approach for modeling and evolutionary strategies for solving the associated optimization problem. Results show that the proposed strategy outperforms conventional predictive control both qualitatively and quantitatively.},
author = {Diaz, Pablo and Salas, Juan C. and Cipriano, Aldo and N{\'{u}}{\~{n}}ez, Felipe},
doi = {10.1016/j.mineng.2020.106760},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S089268752030580X-main.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Machine learning,Model predictive control,Paste thickening,Random forest},
number = {July 2020},
title = {{Random forest model predictive control for paste thickening}},
volume = {163},
year = {2021}
}
@article{Langarica2020,
abstract = {The Big Data revolution refers to using a large amount of data to improve decision making. In process control applications, the use of big data techniques has been restricted to complementing classical control schemes as model-based or PID approaches. This work focuses on a model-free purely data-driven control strategy known as Big Data approximating control (BDAC), which was recently introduced in the context of process control. In particular, this work proposes two modifications to the classical BDAC formulation and presents a real implementation of the enhanced BDAC technique to a real industrial paste thickener.},
author = {Langarica, Sa{\'{u}}l and N{\'{u}}{\~{n}}ez, Felipe},
doi = {10.1016/j.ifacol.2020.12.718},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S2405896320310363-main.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Big data,Cyber-physical systems,Industrial automation,Process control},
number = {2},
pages = {11944--11949},
title = {{Enhanced big data approximating control of an industrial paste thickener}},
volume = {53},
year = {2020}
}
@article{Member2021,
author = {Member, Student},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Neuroevolutive_Control_of_Industrial_Processes_Through_Mapping_Elites.pdf:pdf},
isbn = {2020212005},
number = {5},
pages = {3703--3713},
title = {{Neuroevolutive Control of Industrial}},
volume = {17},
year = {2021}
}
@article{Lesort2018,
abstract = {Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. The representation is learned to capture the variation in the environment generated by the agent's actions; this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension characteristic of the representation helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning. This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.},
archivePrefix = {arXiv},
arxivId = {1802.04181},
author = {Lesort, Timoth{\'{e}}e and D{\'{i}}az-Rodr{\'{i}}guez, Natalia and Goudou, Jean Frano̧is and Filliat, David},
doi = {10.1016/j.neunet.2018.07.006},
eprint = {1802.04181},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S0893608018302053-main(2).pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Disentanglement of control factors,Learning disentangled representations,Low dimensional embedding learning,Reinforcement learning,Robotics,State representation learning},
pages = {379--392},
pmid = {30268059},
title = {{State representation learning for control: An overview}},
volume = {108},
year = {2018}
}
@article{Marino2019,
abstract = {Artificial neural networks (ANNs) have been frequently used in
industrial applications to model complex systems. However, using
traditional ANNs for longterm planning tasks remains a challenge as they
lack the capability to model uncertainty. Process noise and
approximation errors cause ANN long-term estimations to deviate from the
real behavior of the system. Unlike traditional ANNs, stochastic models
provide a natural way to model uncertainty, providing estimations over a
range of several possible outcomes. This paper introduces a stochastic
modeling and planning approach using deep Bayesian neural networks
(DBNNs). We use DBNNs to learn a stochastic model of the system
dynamics. Planning is addressed as an open-loop trajectory optimization
problem. We present two approaches for learning the dynamics: using
single-step predictions and using multistep predictions. The advantages
of the proposed methodology are as follows. First, accurate long-term
estimations of the system state-trajectory probability distribution
without the need for expert knowledge of the dynamics. Second, improved
generalization and faster convergence rates in the trajectory
optimization task when using multistep predictions to train the model.
Third, viable for real-world applications since all expensive
optimizations are executed offline while using a reasonable number of
data samples. Testing is performed using challenging underactuated
benchmark problems: the Cartpole and the Acrobot. The presented
methodology successfully learns the swing-up maneuver using a relatively
small number of iterations, with less than 125 sampled trajectories, and
without any expert knowledge of the dynamics.},
author = {Marino, Daniel L. and Manic, Milos},
doi = {10.1109/tii.2019.2917520},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Modeling_and_Planning_Under_Uncertainty_Using_Deep_Neural_Networks.pdf:pdf},
issn = {1551-3203},
journal = {IEEE Transactions on Industrial Informatics},
number = {8},
pages = {4442--4454},
title = {{Modeling and Planning Under Uncertainty Using Deep Neural Networks}},
volume = {15},
year = {2019}
}
@inproceedings{Jaques2021,
  title={Newtonianvae: Proportional control and goal identification from pixels via physical latent spaces},
  author={Jaques, Miguel and Burke, Michael and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4454--4463},
  year={2021}
}

@phdthesis{kidger2021,
    title={{O}n {N}eural {D}ifferential {E}quations},
    author={Patrick Kidger},
    year={2021},
    school={University of Oxford},
}

@article{chen2018neuralode,
  title={Neural Ordinary Differential Equations},
  author={Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{politorchdyn,
  title={TorchDyn: Implicit Models and Neural Numerical Methods in PyTorch},
  author={Poli, Michael and Massaroli, Stefano and Yamashita, Atsushi and Asama, Hajime and Park, Jinkyoo and Ermon, Stefano}
}

@article{Yuan2022,
author = {Yuan, Zhaolin and Li, Xiaorui and Wu, Di and Ban, Xiaojuan and Wu, Naiqi and Dai, Hong-ning and Wang, Hao},
doi = {10.1109/JAS.2022.105464},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/发表版0210.pdf:pdf},
issn = {2329-9266},
journal = {IEEE/CAA Journal of Automatica Sinica},
mendeley-groups = {myself},
month = {apr},
number = {4},
pages = {686--698},
title = {{Continuous-Time Prediction of Industrial Paste Thickener System With Differential ODE-Net}},
url = {https://ieeexplore.ieee.org/document/9732304/},
volume = {9},
year = {2022}
}
@article{Che2018,
  title={Recurrent neural networks for multivariate time series with missing values},
  author={Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{Langlois2019,
abstract = {The purpose of this paper is to extend existing mathematical models of tailings rheology and sedimentation to form a complete dynamic simulator. It is complete in the sense that it includes all important rheological variables for the development of multivariable control strategies and can be integrated with other stages of tailings management systems. This work extends a one-dimensional model for the dynamics of a flocculated suspension in a clarifier-thickener to include the discharge yield stress and particle size distribution in a manner that is computationally tractable. The paper also extends a static yield stress model to include the effect of particle size distribution, in a manner that is consistent with previous empirical and theoretical evidence. The dynamic simulator is validated through the simulation of a Proportional-Integral control strategy and proves to be a useful and flexible tool for the development of control strategies.},
author = {Langlois, Juan I. and Cipriano, Aldo},
doi = {10.1016/j.mineng.2018.11.006},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Dynamic modeling and simulation of tailing thickener units for the development of control strategies_.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Dynamic simulation,Flocculation,Numerical simulation,Particle size distribution,Sedimentation-consolidation model,Yield stress},
number = {May 2018},
pages = {131--139},
title = {{Dynamic modeling and simulation of tailing thickener units for the development of control strategies.}},
volume = {131},
year = {2019}
}
@article{Langarica2020,
abstract = {The Big Data revolution refers to using a large amount of data to improve decision making. In process control applications, the use of big data techniques has been restricted to complementing classical control schemes as model-based or PID approaches. This work focuses on a model-free purely data-driven control strategy known as Big Data approximating control (BDAC), which was recently introduced in the context of process control. In particular, this work proposes two modifications to the classical BDAC formulation and presents a real implementation of the enhanced BDAC technique to a real industrial paste thickener.},
author = {Langarica, Sa{\'{u}}l and N{\'{u}}{\~{n}}ez, Felipe},
doi = {10.1016/j.ifacol.2020.12.718},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S2405896320310363-main.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Big data,Cyber-physical systems,Industrial automation,Process control},
number = {2},
pages = {11944--11949},
title = {{Enhanced big data approximating control of an industrial paste thickener}},
volume = {53},
year = {2020}
}
@inproceedings{Oulhiq2021,
  title={Identification and control of an industrial thickener using historical data},
  author={Oulhiq, Ridouane and Benjelloun, Khalid and Kali, Yassine and Saad, Maarouf},
  booktitle={2021 18th International Multi-Conference on Systems, Signals \& Devices (SSD)},
  pages={915--920},
  year={2021},
  organization={IEEE}
}
@article{Shin2020,
abstract = {Over the past few decades, advanced process control (APC) such as model predictive control (MPC) has been introduced to process industry to enhance its operational efficiency. For this, a linear model has been widely used to reduce the computational burden for iterative simulation and optimization over time, but it caused high inaccuracy of the control system. In this study, an artificial neural network (ANN) model was adopted instead of using the existing linearized model in order to increase the speed of optimization and accuracy of the model. For a case study, a depropanizer was modeled using Aspen HYSYS, and all feasible operation scenarios were considered to generate massive amounts of dynamic simulation data. Then, the accumulated data was implemented to the ANN for training, and it was tested. Once the verification was completed, the model was incorporated with an optimization algorithm in MPC system. For testing its performance, set point change and introduction of disturbances were applied to the model, and efficiency of the MPC was compared with the conventional control such as PID feedback control. The analysis results showed better performance (i.e., shorter settling time and rise time) of the MPC against the PID control. This methodology can be widely used in various types of control systems in the industry.},
author = {Shin, Yeonju and Smith, Robin and Hwang, Sungwon},
doi = {10.1016/j.jclepro.2020.124124},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S095965262034169X-main.pdf:pdf},
issn = {09596526},
journal = {Journal of Cleaner Production},
keywords = {Artificial neural networks,Model predictive control,Modeling,Optimization},
pages = {124124},
publisher = {Elsevier Ltd},
title = {{Development of model predictive control system using an artificial neural network: A case study with a distillation column}},
url = {https://doi.org/10.1016/j.jclepro.2020.124124},
volume = {277},
year = {2020}
}
@article{Member2021,
author = {Member, Student},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Neuroevolutive_Control_of_Industrial_Processes_Through_Mapping_Elites.pdf:pdf},
isbn = {2020212005},
number = {5},
pages = {3703--3713},
title = {{Neuroevolutive Control of Industrial}},
volume = {17},
year = {2021}
}
@article{Li2018,
abstract = {To ensure undisrupted web-based services, operators need to closely monitor various KPIs (Key Performance Indicator, such as CPU usages, network throughput, page views, number of online users, and etc), detect anomalies in them, and trigger timely troubleshooting or mitigation. There can be hundreds of thousands to even millions of KPIs to be monitored, thus operators need automatic anomaly detection approaches. However, neither traditional statistical approaches nor supervised ensemble approaches satisfy this requirement in practice when facing large number of KPIs. A state-of-art unsupervised approach Donut offering promising results, but it is not a sequential model thus cannot deal with the time information related anomalies. Thus, in this paper we propose Bagel, a robust and unsupervised anomaly detection algorithm for KPI that can handle time information related anomalies, using CVAE to incorporate time information and dropout layer to avoid overfitting. Our experiments using real data from Internet companies show that, compared to Donut, Bagel improves the anomaly detection best F1-score by 0.08 to 0.43.},
author = {Li, Zeyan and Chen, Wenxiao and Pei, Dan},
doi = {10.1109/PCCC.2018.8710885},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Robust and Unsupervised KPI Anomaly Detection.pdf:pdf},
isbn = {9781538668085},
journal = {2018 IEEE 37th International Performance Computing and Communications Conference, IPCCC 2018},
title = {{Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder}},
year = {2018}
}
@inproceedings{Xu2018,
  title={Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications},
  author={Xu, Haowen and Chen, Wenxiao and Zhao, Nengwen and Li, Zeyan and Bu, Jiahao and Li, Zhihan and Liu, Ying and Zhao, Youjian and Pei, Dan and Feng, Yang and others},
  booktitle={Proceedings of the 2018 world wide web conference},
  pages={187--196},
  year={2018}
}

@article{Marino2019,
abstract = {Artificial neural networks (ANNs) have been frequently used in
industrial applications to model complex systems. However, using
traditional ANNs for longterm planning tasks remains a challenge as they
lack the capability to model uncertainty. Process noise and
approximation errors cause ANN long-term estimations to deviate from the
real behavior of the system. Unlike traditional ANNs, stochastic models
provide a natural way to model uncertainty, providing estimations over a
range of several possible outcomes. This paper introduces a stochastic
modeling and planning approach using deep Bayesian neural networks
(DBNNs). We use DBNNs to learn a stochastic model of the system
dynamics. Planning is addressed as an open-loop trajectory optimization
problem. We present two approaches for learning the dynamics: using
single-step predictions and using multistep predictions. The advantages
of the proposed methodology are as follows. First, accurate long-term
estimations of the system state-trajectory probability distribution
without the need for expert knowledge of the dynamics. Second, improved
generalization and faster convergence rates in the trajectory
optimization task when using multistep predictions to train the model.
Third, viable for real-world applications since all expensive
optimizations are executed offline while using a reasonable number of
data samples. Testing is performed using challenging underactuated
benchmark problems: the Cartpole and the Acrobot. The presented
methodology successfully learns the swing-up maneuver using a relatively
small number of iterations, with less than 125 sampled trajectories, and
without any expert knowledge of the dynamics.},
author = {Marino, Daniel L. and Manic, Milos},
doi = {10.1109/tii.2019.2917520},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Modeling_and_Planning_Under_Uncertainty_Using_Deep_Neural_Networks.pdf:pdf},
issn = {1551-3203},
journal = {IEEE Transactions on Industrial Informatics},
number = {8},
pages = {4442--4454},
title = {{Modeling and Planning Under Uncertainty Using Deep Neural Networks}},
volume = {15},
year = {2019}
}
@article{Diaz2021,
abstract = {As processes involved in mineral processing operations increase their complexity, automation and control become critical to ensure an economically viable and environmentally sustainable operation. In the context of modern mineral processing, paste thickening stands out as a relatively new method for producing high density slurries that has proven challenging for standard control algorithms. In this setting, the use of machine-learning-based models within a predictive control strategy arises as an appealing alternative. This work presents a Random Forest Model Predictive Control scheme for paste thickening based on a purely data-driven approach for modeling and evolutionary strategies for solving the associated optimization problem. Results show that the proposed strategy outperforms conventional predictive control both qualitatively and quantitatively.},
author = {Diaz, Pablo and Salas, Juan C. and Cipriano, Aldo and N{\'{u}}{\~{n}}ez, Felipe},
doi = {10.1016/j.mineng.2020.106760},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S089268752030580X-main.pdf:pdf},
issn = {08926875},
journal = {Minerals Engineering},
keywords = {Machine learning,Model predictive control,Paste thickening,Random forest},
number = {July 2020},
title = {{Random forest model predictive control for paste thickening}},
volume = {163},
year = {2021}
}
@inproceedings{Li2018a,
  title={Disentangled sequential autoencoder},
  author={Yingzhen, Li and Mandt, Stephan},
  booktitle={International Conference on Machine Learning},
  pages={5670--5679},
  year={2018},
  organization={PMLR}
}
@inproceedings{VSDN_Liu2020,
  title={Continuous-Time Stochastic Differential Networks for Irregular Time Series Modeling},
  author={Liu, Yingru and Xing, Yucheng and Yang, Xuewen and Wang, Xin and Shi, Jing and Jin, Di and Chen, Zhaoyue and Wu, Jacqueline},
  booktitle={International Conference on Neural Information Processing},
  pages={343--351},
  year={2021},
  organization={Springer}
}

@article{Lee2019,
  title={Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model},
  author={Lee, Alex X and Nagabandi, Anusha and Abbeel, Pieter and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={741--752},
  year={2020}
}
@article{Lesort2018,
abstract = {Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. The representation is learned to capture the variation in the environment generated by the agent's actions; this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension characteristic of the representation helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning. This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.},
archivePrefix = {arXiv},
arxivId = {1802.04181},
author = {Lesort, Timoth{\'{e}}e and D{\'{i}}az-Rodr{\'{i}}guez, Natalia and Goudou, Jean Frano̧is and Filliat, David},
doi = {10.1016/j.neunet.2018.07.006},
eprint = {1802.04181},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/1-s2.0-S0893608018302053-main(2).pdf:pdf},
issn = {18792782},
journal = {Neural Networks},
keywords = {Disentanglement of control factors,Learning disentangled representations,Low dimensional embedding learning,Reinforcement learning,Robotics,State representation learning},
pages = {379--392},
pmid = {30268059},
title = {{State representation learning for control: An overview}},
volume = {108},
year = {2018}
}
@article{Gedon,
  title={Deep state space models for nonlinear system identification},
  author={Gedon, Daniel and Wahlstr{\"o}m, Niklas and Sch{\"o}n, Thomas B and Ljung, Lennart},
  journal={IFAC-PapersOnLine},
  volume={54},
  number={7},
  pages={481--486},
  year={2021},
  publisher={Elsevier}
}

@article{Rubanova2019,
abstract = {Time series with non-uniform intervals occur in many applications, and are difficult to model using standard recurrent neural networks (RNNs). We generalize RNNs to have continuous-time hidden dynamics defined by ordinary differential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs to replace the recognition network of the recently-proposed Latent ODE model. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps between observations, and can explicitly model the probability of observation times using Poisson processes. We show experimentally that these ODE-based models outperform their RNN-based counterparts on irregularly-sampled data.},
archivePrefix = {arXiv},
arxivId = {1907.03907},
author = {Rubanova, Yulia and Chen, Ricky T.Q. and Duvenaud, David},
eprint = {1907.03907},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/NeurIPS-2019-latent-ordinary-differential-equations-for-irregularly-sampled-time-series-Paper.pdf:pdf;:Users/yuanzhaolin/Documents/Mendeley Desktop/supplement_updated.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
title = {{Latent ODEs for irregularly-sampled time series}},
volume = {32},
year = {2019}
}



@inproceedings{Quaglino2019,
 author = {Alessio Quaglino and
Marco Gallieri and
Jonathan Masci and
Jan Koutn{\'{\i}}k},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/QuaglinoGMK20.bib},
 booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
Addis Ababa, Ethiopia, April 26-30, 2020},
 publisher = {OpenReview.net},
 timestamp = {Thu, 07 May 2020 01:00:00 +0200},
 title = {{SNODE:} Spectral Discretization of Neural ODEs for System Identification},
 url = {https://openreview.net/forum?id=Sye0XkBKvS},
 year = {2020}
}

@article{aastrom1971system,
  title={System identification—a survey},
  author={{\AA}str{\"o}m, Karl Johan and Eykhoff, Peter},
  journal={Automatica},
  volume={7},
  number={2},
  pages={123--162},
  year={1971},
  publisher={Elsevier}
}

@inproceedings{wang2017new,
  title={A new concept using lstm neural networks for dynamic system identification},
  author={Wang, Yu},
  booktitle={2017 American control conference (ACC)},
  pages={5324--5329},
  year={2017},
  organization={IEEE}
}
@article{ogunmolu2016nonlinear,
  title={Nonlinear systems identification using deep dynamic neural networks},
  author={Ogunmolu, Olalekan and Gu, Xuejun and Jiang, Steve and Gans, Nicholas},
  journal={arXiv preprint arXiv:1610.01439},
  year={2016}
}

@inproceedings{zhong2019symplectic,
  title={Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control},
  author={Zhong, Yaofeng Desmond and Dey, Biswadip and Chakraborty, Amit},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{lesort2018state,
  title={State representation learning for control: An overview},
  author={Lesort, Timoth{\'e}e and D{\'\i}az-Rodr{\'\i}guez, Natalia and Goudou, Jean-Franois and Filliat, David},
  journal={Neural Networks},
  volume={108},
  pages={379--392},
  year={2018},
  publisher={Elsevier}
}
@inproceedings{kingma2013auto,
 author = {Diederik P. Kingma and
Max Welling},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
 booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
 editor = {Yoshua Bengio and
Yann LeCun},
 timestamp = {Fri, 29 Mar 2019 00:00:00 +0100},
 title = {Auto-Encoding Variational Bayes},
 url = {http://arxiv.org/abs/1312.6114},
 year = {2014}
}
@article{Fraccaro2016,
  title={Sequential neural models with stochastic layers},
  author={Fraccaro, Marco and S{\o}nderby, S{\o}ren Kaae and Paquet, Ulrich and Winther, Ole},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@article{Chung2015,
  title={A recurrent latent variable model for sequential data},
  author={Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron C and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{Karl2017,
 author = {Maximilian Karl and
Maximilian Soelch and
Justin Bayer and
Patrick van der Smagt},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/KarlSBS17.bib},
 booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
Toulon, France, April 24-26, 2017, Conference Track Proceedings},
 publisher = {OpenReview.net},
 timestamp = {Mon, 31 Aug 2020 01:00:00 +0200},
 title = {Deep Variational Bayes Filters: Unsupervised Learning of State Space
Models from Raw Data},
 url = {https://openreview.net/forum?id=HyTqHL5xg},
 year = {2017}
}
@inproceedings{yildiz2021continuous,
  title={Continuous-time Model-based Reinforcement Learning},
  author={Yildiz, Cagatay and Heinonen, Markus and L{\"a}hdesm{\"a}ki, Harri},
  booktitle={International Conference on Machine Learning},
  pages={12009--12018},
  year={2021},
  organization={PMLR}
}
@inproceedings{doerr2018probabilistic,
  title={Probabilistic recurrent state-space models},
  author={Doerr, Andreas and Daniel, Christian and Schiegg, Martin and Duy, Nguyen-Tuong and Schaal, Stefan and Toussaint, Marc and Sebastian, Trimpe},
  booktitle={International Conference on Machine Learning},
  pages={1280--1289},
  year={2018},
  organization={PMLR}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}
@inproceedings{venkatraman2015improving,
  title={Improving multi-step prediction of learned time series models},
  author={Venkatraman, Arun and Hebert, Martial and Bagnell, J Andrew},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}
@article{Guo2019,
author = {Guo, Xinxin and Yan, Weisheng and Cui, Rongxin},
doi = {10.1109/tsmc.2019.2897221},
file = {:Users/yuanzhaolin/Documents/Mendeley Desktop/Guo, Yan, Cui - 2019 - Integral Reinforcement Learning-Based Adaptive NN Control for Continuous-Time Nonlinear MIMO Systems With Unknown.pdf:pdf},
issn = {2168-2216},
journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
mendeley-groups = {IRL},
pages = {1--10},
publisher = {IEEE},
title = {{Integral Reinforcement Learning-Based Adaptive NN Control for Continuous-Time Nonlinear MIMO Systems With Unknown Control Directions}},
volume = {PP},
year = {2019}
}

@ARTICLE{8709809,
  author={Yang, Hongyan and Yin, Shen},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Actuator and Sensor Fault Estimation for Time-Delay Markov Jump Systems With Application to Wheeled Mobile Manipulators}, 
  year={2020},
  volume={16},
  number={5},
  pages={3222-3232},
  doi={10.1109/TII.2019.2915668}}
@article{song2015almost,
  title={Almost sure stability of switching Markov jump linear systems},
  author={Song, Yang and Yang, Jie and Yang, Taicheng and Fei, Minrui},
  journal={IEEE Transactions on Automatic Control},
  volume={61},
  number={9},
  pages={2638--2643},
  year={2015},
  publisher={IEEE}
}
  @ARTICLE{9165930,
  author={Wang, Yu and He, Long and Jiang, Shan and Chow, Tommy W. S.},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Failure Prediction of Hard Disk Drives Based on Adaptive Rao–Blackwellized Particle Filter Error Tracking Method}, 
  year={2021},
  volume={17},
  number={2},
  pages={913-921},
  doi={10.1109/TII.2020.3016121}}
@InProceedings{pmlr-v120-jansch-porto20a,
  title = 	 {Policy Learning of MDPs with Mixed Continuous/Discrete Variables: A Case Study on  Model-Free Control of Markovian Jump Systems},
  author =       {Jansch-Porto, Joao Paulo and Hu, Bin and Dullerud, Geir},
  booktitle = 	 {Proceedings of the 2nd Conference on Learning for Dynamics and Control},
  pages = 	 {947--957},
  year = 	 {2020},
  editor = 	 {Bayen, Alexandre M. and Jadbabaie, Ali and Pappas, George and Parrilo, Pablo A. and Recht, Benjamin and Tomlin, Claire and Zeilinger, Melanie},
  volume = 	 {120},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--11 Jun},
  publisher =    {PMLR},
}

  @article{song2015almost,
  title={Almost sure stability of switching Markov jump linear systems},
  author={Song, Yang and Yang, Jie and Yang, Taicheng and Fei, Minrui},
  journal={IEEE Transactions on Automatic Control},
  volume={61},
  number={9},
  pages={2638--2643},
  year={2015},
  publisher={IEEE}
}
@article{zadeh1956identification,
  title={On the identification problem},
  author={Zadeh, L},
  journal={IRE Transactions on Circuit Theory},
  volume={3},
  number={4},
  pages={277--281},
  year={1956},
  publisher={IEEE}
}
@article{jordan1992forward,
  title={Forward models: Supervised learning with a distal teacher},
  author={Jordan, Michael I and Rumelhart, David E},
  journal={Cognitive science},
  volume={16},
  number={3},
  pages={307--354},
  year={1992},
  publisher={Elsevier}
}
@inproceedings{silver2008sample,
  title={Sample-based learning and search with permanent and transient memories},
  author={Silver, David and Sutton, Richard S and M{\"u}ller, Martin},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={968--975},
  year={2008}
}
@inproceedings{werbos1989neural,
  title={Neural networks for control and system identification},
  author={Werbos, Paul J},
  booktitle={Proceedings of the 28th IEEE Conference on Decision and Control,},
  pages={260--265},
  year={1989},
  organization={IEEE}
}
@book{lin1992memory,
  title={Memory approaches to reinforcement learning in non-Markovian domains},
  author={Lin, Long-Ji and Mitchell, Tom M},
  year={1992},
  publisher={Citeseer}
}
@article{WANG2022111790,
title = {Model and data driven transient thermal system modelings for contained data centers},
journal = {Energy and Buildings},
volume = {258},
pages = {111790},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111790},
author = {Yewan Wang and Yiru Zhang and David Nörtershäuser and Stéphane {Le Masson} and Jean-Marc Menaud},
}
@article{balenzuela2022parameter,
  title={Parameter estimation for Jump Markov Linear Systems},
  author={Balenzuela, Mark P and Wills, Adrian G and Renton, Christopher and Ninness, Brett},
  journal={Automatica},
  volume={135},
  pages={109949},
  year={2022},
  publisher={Elsevier}
}
@inproceedings{takahashi2021differentiable,
  title={Differentiable fluids with solid coupling for learning and control},
  author={Takahashi, Tetsuya and Liang, Junbang and Qiao, Yi-Ling and Lin, Ming C},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={7},
  pages={6138--6146},
  year={2021}
}
@inproceedings{li2020fourier,
  title={Fourier Neural Operator for Parametric Partial Differential Equations},
  author={Li, Zongyi and Kovachki, Nikola Borislavov and Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{jia2019neural,
  title={Neural jump stochastic differential equations},
  author={Jia, Junteng and Benson, Austin R},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{ashley2014sequential,
  title={A sequential Monte Carlo framework for the system identification of jump Markov state space models},
  author={Ashley, Trevor T and Andersson, Sean B},
  booktitle={2014 American Control Conference},
  pages={1144--1149},
  year={2014},
  organization={IEEE}
}
@article{opper2007variational,
  title={Variational inference for Markov jump processes},
  author={Opper, Manfred and Sanguinetti, Guido},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}
@article{fang2002stabilization,
  title={Stabilization of continuous-time jump linear systems},
  author={Fang, Yuguang and Loparo, Kenneth A},
  journal={IEEE Transactions on Automatic Control},
  volume={47},
  number={10},
  pages={1590--1603},
  year={2002},
  publisher={IEEE}
}
@inproceedings{svensson2014identification,
  title={Identification of jump Markov linear models using particle filters},
  author={Svensson, Andreas and Sch{\"o}n, Thomas B and Lindsten, Fredrik},
  booktitle={53rd IEEE conference on decision and control},
  pages={6504--6509},
  year={2014},
  organization={IEEE}
}
@article{ling2016reynolds,
  title={Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
  author={Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
  journal={Journal of Fluid Mechanics},
  volume={807},
  pages={155--166},
  year={2016},
  publisher={Cambridge University Press}
}

@online{rackauckas2020universal,
  title={Universal differential equations for scientific machine learning},
  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali and Edelman, Alan},
  journal={arXiv preprint arXiv:2001.04385},
  url={https://arxiv.org/abs/2001.04385},
  doi={,},
  year={2020}
}
@article{ramadhan2020capturing,
  title={Capturing missing physics in climate model parameterizations using neural differential equations},
  author={Ramadhan, Ali and Marshall, John and Souza, Andre and Wagner, Gregory LeClaire and Ponnapati, Manvitha and Rackauckas, Christopher},
  journal={arXiv preprint arXiv:2010.12559},
  url={https://arxiv.org/abs/2010.12559},
  doi={,},
  year={2020}
}
@book{powell2007approximate,
  title={Approximate Dynamic Programming: Solving the curses of dimensionality},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}
@book{zhang2012adaptive,
  title={Adaptive dynamic programming for control: algorithms and stability},
  author={Zhang, Huaguang and Liu, Derong and Luo, Yanhong and Wang, Ding},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@article{abu2005nearly,
  title={Nearly optimal control laws for nonlinear systems with saturating actuators using a neural network HJB approach},
  author={Abu-Khalaf, Murad and Lewis, Frank L},
  journal={Automatica},
  volume={41},
  number={5},
  pages={779--791},
  year={2005},
  publisher={Elsevier}
}
@article{vrabie2009neural,
  title={Neural network approach to continuous-time direct adaptive optimal control for partially unknown nonlinear systems},
  author={Vrabie, Draguna and Lewis, Frank},
  journal={Neural Networks},
  volume={22},
  number={3},
  pages={237--246},
  year={2009},
  publisher={Elsevier}
}
@article{vamvoudakis2014online,
  title={Online adaptive algorithm for optimal control with integral reinforcement learning},
  author={Vamvoudakis, Kyriakos G and Vrabie, Draguna and Lewis, Frank L},
  journal={International Journal of Robust and Nonlinear Control},
  volume={24},
  number={17},
  pages={2686--2710},
  year={2014},
  publisher={Wiley Online Library}
}
@article{zhang2008novel,
  title={A novel infinite-time optimal tracking control scheme for a class of discrete-time nonlinear systems via the greedy HDP iteration algorithm},
  author={Zhang, Huaguang and Wei, Qinglai and Luo, Yanhong},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={38},
  number={4},
  pages={937--942},
  year={2008},
  publisher={IEEE}
}
@article{kamalapurkar2015approximate,
  title={Approximate optimal trajectory tracking for continuous-time nonlinear systems},
  author={Kamalapurkar, Rushikesh and Dinh, Huyen and Bhasin, Shubhendu and Dixon, Warren E},
  journal={Automatica},
  volume={51},
  pages={40--48},
  year={2015},
  publisher={Elsevier}
}
@article{modares2014linear,
  title={Linear quadratic tracking control of partially-unknown continuous-time systems using reinforcement learning},
  author={Modares, Hamidreza and Lewis, Frank L},
  journal={IEEE Transactions on Automatic control},
  volume={59},
  number={11},
  pages={3051--3056},
  year={2014},
  publisher={IEEE}
}
@article{modares2014optimal,
  title={Optimal tracking control of nonlinear partially-unknown constrained-input systems using integral reinforcement learning},
  author={Modares, Hamidreza and Lewis, Frank L},
  journal={Automatica},
  volume={50},
  number={7},
  pages={1780--1792},
  year={2014},
  publisher={Elsevier}
}
@article{jiang2012computational,
  title={Computational adaptive optimal control for continuous-time linear systems with completely unknown dynamics},
  author={Jiang, Yu and Jiang, Zhong-Ping},
  journal={Automatica},
  volume={48},
  number={10},
  pages={2699--2704},
  year={2012},
  publisher={Elsevier}
}
@article{modares2015h,
  title={H∞ Tracking control of completely unknown continuous-time systems via off-policy reinforcement learning},
  author={Modares, Hamidreza and Lewis, Frank L and Jiang, Zhong-Ping},
  journal={IEEE transactions on neural networks and learning systems},
  volume={26},
  number={10},
  pages={2550--2562},
  year={2015},
  publisher={IEEE}
}
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@INPROCEEDINGS{7983780,
  author={Spielberg, S.P.K. and Gopaluni, R.B. and Loewen, P.D.},
  booktitle={2017 6th International Symposium on Advanced Control of Industrial Processes (AdCONIP)}, 
  title={Deep reinforcement learning approaches for process control}, 
  year={2017},
  volume={},
  number={},
  pages={201-206},
  doi={10.1109/ADCONIP.2017.7983780}}
@inproceedings{yu2017deep,
  title={Deep reinforcement learning based optimal trajectory tracking control of autonomous underwater vehicle},
  author={Yu, Runsheng and Shi, Zhenyu and Huang, Chaoxing and Li, Tenglong and Ma, Qiongxiong},
  booktitle={2017 36th Chinese control conference (CCC)},
  pages={4958--4965},
  year={2017},
  organization={IEEE}
}
@article{kim2018deep,
  title={Deep reinforcement learning based finite-horizon optimal tracking control for nonlinear system},
  author={Kim, Jong Woo and Park, Byung Jun and Yoo, Haeun and Lee, Jay H and Lee, Jong Min},
  journal={IFAC-PapersOnLine},
  volume={51},
  number={25},
  pages={257--262},
  year={2018},
  publisher={Elsevier}
}
@article{kim2020model,
  title={A model-based deep reinforcement learning method applied to finite-horizon optimal control of nonlinear control-affine system},
  author={Kim, Jong Woo and Park, Byung Jun and Yoo, Haeun and Oh, Tae Hoon and Lee, Jay H and Lee, Jong Min},
  journal={Journal of Process Control},
  volume={87},
  pages={166--178},
  year={2020},
  publisher={Elsevier}
}
@article{lecun2022path,
  title={A Path Towards Autonomous Machine Intelligence Version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  year={2022}
}
@online{moerland2020model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:2006.16712},
  url={https://arxiv.org/abs/2006.16712},
  doi={,},
  year={2020}
}
@INPROCEEDINGS{6859280,
  author={Ashley, Trevor T. and Andersson, Sean B.},
  booktitle={2014 American Control Conference}, 
  title={A Sequential Monte Carlo framework for the system identification of jump Markov state space models}, 
  year={2014},
  volume={},
  number={},
  pages={1144-1149},
  doi={10.1109/ACC.2014.6859280}}

@article{Yilmaz2007,
author = {Yilmaz, Sezayi and Atik, Kemal},
doi = {10.1016/j.applthermaleng.2007.01.030},
issn = {13594311},
journal = {Applied Thermal Engineering},
keywords = {Artificial neural networks,Condenser temperature,Cooling cycle},
mendeley-groups = {cooling},
number = {13},
pages = {2308--2313},
title = {{Modeling of a mechanical cooling system with variable cooling capacity by using artificial neural network}},
volume = {27},
year = {2007}
}
@article{Watter2015,
author = {Watter, Manuel and Springenberg, Jost Tobias and Boedecker, Joschka and Riedmiller, Martin},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {VAE},
pages = {2746--2754},
title = {{Embed to control: A locally linear latent dynamics model for control from raw images}},
volume = {2015-Janua},
year = {2015}
}
@article{song2015data,
  title={Data center energy and cost saving evaluation},
  author={Song, Zz and Zhang, Xiaojing and Eriksson, Clas},
  journal={Energy Procedia},
  volume={75},
  pages={1255--1260},
  year={2015},
  publisher={Elsevier}
}
@inproceedings{10.1145/3097983.3098060,
author = {Hallac, David and Vare, Sagar and Boyd, Stephen and Leskovec, Jure},
title = {Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series Data},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098060},
doi = {10.1145/3097983.3098060},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {215–223},
numpages = {9},
keywords = {networks, alternating minimization, time series analysis, clustering, convex optimization},
location = {Halifax, NS, Canada},
series = {KDD '17}
}
@article{LI2021109687,
title = {A novel adaptive dynamic programming based on tracking error for nonlinear discrete-time systems},
journal = {Automatica},
volume = {129},
pages = {109687},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2021.109687},
url = {https://www.sciencedirect.com/science/article/pii/S0005109821002077},
author = {Chun Li and Jinliang Ding and Frank L. Lewis and Tianyou Chai},
keywords = {Adaptive dynamic programming (ADP), Tracking problem (TP), Optimal control policy, Value iteration (VI), Policy iteration (PI)},
}
@inproceedings{hafner2019dream,
 author = {Danijar Hafner and
Timothy P. Lillicrap and
Jimmy Ba and
Mohammad Norouzi},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/HafnerLB020.bib},
 booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
Addis Ababa, Ethiopia, April 26-30, 2020},
 publisher = {OpenReview.net},
 timestamp = {Thu, 07 May 2020 01:00:00 +0200},
 title = {Dream to Control: Learning Behaviors by Latent Imagination},
 url = {https://openreview.net/forum?id=S1lOTC4tDS},
 year = {2020}
}
@online{lai2015giraffe,
 author = {Lai, Matthew},
 journal = {arXiv preprint arXiv:1509.01549},
 title = {Giraffe: Using deep reinforcement learning to play chess},
 year = {2015},
 doi = {,}
}
@inproceedings{franccois2019combined,
  title={Combined reinforcement learning via abstract representations},
  author={Fran{\c{c}}ois-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3582--3589},
  year={2019}
}
@online{baxter1999tdleaf,
 author = {Baxter, Jonathan and Tridgell, Andrew and Weaver, Lex},
 journal = {arXiv preprint cs/9901001},
 title = {Tdleaf (lambda): Combining temporal difference learning with game-tree search},
 year = {1999},
 doi ={,}
}
@incollection{sutton1990integrated,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning proceedings 1990},
  pages={216--224},
  year={1990},
  publisher={Elsevier}
}
@article{degrave2019differentiable,
  title={A differentiable physics engine for deep learning in robotics},
  author={Degrave, Jonas and Hermans, Michiel and Dambre, Joni and others},
  journal={Frontiers in neurorobotics},
  pages={6},
  year={2019},
  publisher={Frontiers}
}
@article{de2018end,
  title={End-to-end differentiable physics for learning and control},
  author={de Avila Belbute-Peres, Filipe and Smith, Kevin and Allen, Kelsey and Tenenbaum, Josh and Kolter, J Zico},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{NIPS2014_6766aa27,
	author = {Levine, Sergey and Abbeel, Pieter},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
	url = {https://proceedings.neurips.cc/paper/2014/file/6766aa2750c19aad2fa1b32f36ed4aee-Paper.pdf},
	volume = {27},
	year = {2014},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2014/file/6766aa2750c19aad2fa1b32f36ed4aee-Paper.pdf}}

@inproceedings{mishra2017prediction,
  title={Prediction and control with temporal segment models},
  author={Mishra, Nikhil and Abbeel, Pieter and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={2459--2468},
  year={2017},
  organization={PMLR}
}
@misc{JetsonTX2,
 title={Jetson TX2}, 
howpublished={\url{https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-tx2/}}, 
author={Nvidia}
}